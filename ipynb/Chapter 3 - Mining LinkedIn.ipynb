{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Mining the Social Web, 2nd Edition\n",
      "\n",
      "##Chapter 3: Mining LinkedIn: Faceting Job Titles, Clustering Colleagues, and More\n",
      "\n",
      "This IPython Notebook provides an interactive way to follow along with and explore the numbered examples from [_Mining the Social Web (2nd Edition)_](http://bit.ly/135dHfs). The intent behind this notebook is to reinforce the concepts from the sample code in a fun, convenient, and effective way. This notebook assumes that you are reading along with the book and have the context of the discussion as you work through these exercises.\n",
      "\n",
      "In the somewhat unlikely event that you've somehow stumbled across this notebook outside of its context on GitHub, [you can find the full source code repository here](http://bit.ly/16kGNyb).\n",
      "\n",
      "## Copyright and Licensing\n",
      "\n",
      "You are free to use or adapt this notebook for any purpose you'd like. However, please respect the [Simplified BSD License](https://github.com/ptwobrussell/Mining-the-Social-Web-2nd-Edition/blob/master/LICENSE.txt) that governs its use."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#LinkedIn API Access\n",
      "\n",
      "LinkedIn implements OAuth 2.0 as one of its standard authentication mechanisms, but still supports OAuth 1.0a, which provides you with four credentials (\"API Key\", \"Secret Key\", \"OAuth User Token\", and \"OAuth User Secret\") that can be used to gain instant API access with no further fuss or redirections. You can create an app and retrieve these four credentials through the \"Developer\" section of your account settings as shown below or by navigating directly to https://www.linkedin.com/secure/developer.\n",
      "\n",
      "<img src=\"files/resources/ch03-linkedin/images/LinkedIn-app.png\" width=\"600px\">"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Note that you'll need to install a third-party package called <code>python-linkedin</code> to use the code in this notebook. Installing a package directly from a GitHub repository is easy with pip in the terminal:\n",
      "\n",
      "<code>\n",
      "$ pip install python-linkedin\n",
      "</code>"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Example 1. Using LinkedIn OAuth credentials to receive an access token suitable for development and accessing your own data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from linkedin import linkedin # pip install python-linkedin\n",
      "\n",
      "# Define CONSUMER_KEY, CONSUMER_SECRET,  \n",
      "# USER_TOKEN, and USER_SECRET from the credentials \n",
      "# provided in your LinkedIn application\n",
      "\n",
      "CONSUMER_KEY = '77c7i24if6lpba'\n",
      "CONSUMER_SECRET = 'bW0mLR5pmRADpQU5'\n",
      "USER_TOKEN = '21f984eb-2922-47eb-9aa3-85dbfb671dff'\n",
      "USER_SECRET = 'b882ce5d-d97d-4866-9ac7-a5a7d48c1b18'\n",
      "\n",
      "RETURN_URL = '' # Not required for developer authentication\n",
      "\n",
      "# Instantiate the developer authentication class\n",
      "\n",
      "auth = linkedin.LinkedInDeveloperAuthentication(CONSUMER_KEY, CONSUMER_SECRET, \n",
      "                                USER_TOKEN, USER_SECRET, \n",
      "                                RETURN_URL, \n",
      "                                permissions=linkedin.PERMISSIONS.enums.values())\n",
      "\n",
      "# Pass it in to the app...\n",
      "\n",
      "app = linkedin.LinkedInApplication(auth)\n",
      "\n",
      "# Use the app...\n",
      "\n",
      "app.get_profile()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 1,
       "text": [
        "{u'firstName': u'Christopher',\n",
        " u'headline': u'Product Marketing at Samsung Electronics',\n",
        " u'lastName': u'Tong',\n",
        " u'siteStandardProfileRequest': {u'url': u'http://www.linkedin.com/profile/view?id=61233084&authType=name&authToken=eSsm&trk=api*a3351603*s3423633*'}}"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Example 2. Retrieving your LinkedIn connections and storing them to disk"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import json\n",
      "\n",
      "connections = app.get_connections()\n",
      "\n",
      "connections_data = 'resources/ch03-linkedin/linkedin_connections.json'\n",
      "\n",
      "f = open(connections_data, 'w')\n",
      "f.write(json.dumps(connections, indent=1))\n",
      "f.close()\n",
      "\n",
      "# You can reuse the data without using the API later like this...\n",
      "# connections = json.loads(open(connections_data).read())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Execute this cell if you need to reload data...\n",
      "import json\n",
      "connections = json.loads(open('resources/ch03-linkedin/linkedin_connections.json').read())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Note**: Should you need to revoke account access from your application or any other OAuth application, you can do so at [https://www.linkedin.com/secure/settings?userAgree=&goback=%2Enas_*1_*1_*1](https://www.linkedin.com/secure/settings?userAgree=&goback=%2Enas_*1_*1_*1)"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Example 3. Pretty-printing your LinkedIn connections' data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from prettytable import PrettyTable # pip install prettytable\n",
      "\n",
      "pt = PrettyTable(field_names=['Name', 'Location'])\n",
      "pt.align = 'l'\n",
      "\n",
      "[ pt.add_row((c['firstName'] + ' ' + c['lastName'], c['location']['name'])) \n",
      "  for c in connections['values']\n",
      "      if c.has_key('location') and c.has_key('industry')]\n",
      "\n",
      "print pt\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "+-----------------------------------------+----------------------------------+\n",
        "| Name                                    | Location                         |\n",
        "+-----------------------------------------+----------------------------------+\n",
        "| Jenifyr Lux                             | San Francisco Bay Area           |\n",
        "| Christian Bada                          | San Francisco Bay Area           |\n",
        "| Michelle Williamson                     | San Francisco Bay Area           |\n",
        "| Michael Pachos (\u03a0\u03ac\u03c7\u03bf\u03c2)                  | San Francisco Bay Area           |\n",
        "| Yue Tu                                  | San Francisco Bay Area           |\n",
        "| Ken Singer                              | San Francisco Bay Area           |\n",
        "| Hyunhee (Ryan) Cho                      | Seocho-gu, Seoul, Korea          |\n",
        "| Brian Fukumoto                          | San Francisco Bay Area           |\n",
        "| Chris Moore                             | San Francisco Bay Area           |\n",
        "| Sophia Han                              | San Francisco Bay Area           |\n",
        "| Ric Kostick                             | San Francisco Bay Area           |\n",
        "| James Curleigh                          | San Francisco Bay Area           |\n",
        "| Gina DeAmicis-Krause                    | San Francisco Bay Area           |\n",
        "| Jeremy Fiance                           | San Francisco Bay Area           |\n",
        "| Toni Blank                              | San Francisco Bay Area           |\n",
        "| Jay Subhash                             | San Francisco Bay Area           |\n",
        "| Chip Bergh                              | San Francisco Bay Area           |\n",
        "| Patricia Hayman                         | San Francisco Bay Area           |\n",
        "| David Duchen                            | Greater Seattle Area             |\n",
        "| Alex Go                                 | San Francisco Bay Area           |\n",
        "| Ed Heacox                               | San Francisco Bay Area           |\n",
        "| Pankaj Agarwal                          | Korea                            |\n",
        "| Marjorie DeGraca                        | San Francisco Bay Area           |\n",
        "| John Holgate                            | Washington D.C. Metro Area       |\n",
        "| Summer Sang-a Kim                       | San Francisco Bay Area           |\n",
        "| Beto Guajardo                           | Greater Seattle Area             |\n",
        "| Sarah Brown                             | Greater New York City Area       |\n",
        "| Kyra Johanson                           | San Francisco Bay Area           |\n",
        "| David Park                              | San Francisco Bay Area           |\n",
        "| Leslie Chen                             | San Francisco Bay Area           |\n",
        "| Justin Yu                               | San Francisco Bay Area           |\n",
        "| Kobe Li                                 | San Francisco Bay Area           |\n",
        "| Dawn Miedler                            | San Francisco Bay Area           |\n",
        "| Sylvia Tang                             | San Francisco Bay Area           |\n",
        "| Omar Rehmane                            | San Francisco Bay Area           |\n",
        "| Deanne Chen                             | San Francisco Bay Area           |\n",
        "| Deidre Quan                             | San Francisco Bay Area           |\n",
        "| Tim McAtee                              | San Francisco Bay Area           |\n",
        "| Ivy Lee                                 | San Francisco Bay Area           |\n",
        "| Rosa Huh                                | San Francisco Bay Area           |\n",
        "| Cathy Hwang                             | Greater Boston Area              |\n",
        "| Josephine Tam                           | San Francisco Bay Area           |\n",
        "| Frances Bo                              | San Francisco Bay Area           |\n",
        "| Sevly Snguon                            | San Francisco Bay Area           |\n",
        "| Nguyet Tran                             | San Francisco Bay Area           |\n",
        "| Wendy Wu                                | San Francisco Bay Area           |\n",
        "| Tim Barron                              | San Francisco Bay Area           |\n",
        "| Kang Won Choi                           | Korea                            |\n",
        "| Devon Jue                               | Orange County, California Area   |\n",
        "| Christopher Nguyen                      | San Francisco Bay Area           |\n",
        "| Molly Amble Kihanya                     | Greater Seattle Area             |\n",
        "| Cheng Lu                                | San Francisco Bay Area           |\n",
        "| Simon Tiu                               | San Francisco Bay Area           |\n",
        "| Christina Aoun                          | Greater Los Angeles Area         |\n",
        "| Jessica Lukrich                         | San Francisco Bay Area           |\n",
        "| Jenny Jiang                             | San Francisco Bay Area           |\n",
        "| Jenn Kimbal                             | San Francisco Bay Area           |\n",
        "| Jason Teh                               | San Francisco Bay Area           |\n",
        "| Jesse Krieger                           | San Francisco Bay Area           |\n",
        "| Jenny Tang                              | San Francisco Bay Area           |\n",
        "| David Shulman                           | San Francisco Bay Area           |\n",
        "| Amanda Owyoung                          | San Francisco Bay Area           |\n",
        "| Frank Burgoyne                          | San Francisco Bay Area           |\n",
        "| Patricia Kwan                           | San Francisco Bay Area           |\n",
        "| Casson Trenor                           | San Francisco Bay Area           |\n",
        "| Jay Tong                                | San Francisco Bay Area           |\n",
        "| Glen Chen                               | San Francisco Bay Area           |\n",
        "| Mariona Prat Vila(\ub9c8\ub9ac\uc624\ub098 \ud504\ub77c\ud2b8 \ube4c\ub77c) | Barcelona Area, Spain            |\n",
        "| George Nguyen                           | Orange County, California Area   |\n",
        "| Alan Zheng                              | San Francisco Bay Area           |\n",
        "| Alan Joseph Navarrete Uy                | San Francisco Bay Area           |\n",
        "| Mark Landig, OD                         | Greater Los Angeles Area         |\n",
        "| Anne Chen                               | San Francisco Bay Area           |\n",
        "| Bingze Gu                               | San Francisco Bay Area           |\n",
        "| Geoff Stafford                          | San Francisco Bay Area           |\n",
        "| Mindy Chu                               | Greater Los Angeles Area         |\n",
        "| Roger Clairmont                         | San Francisco Bay Area           |\n",
        "| Phi Nguyen                              | San Francisco Bay Area           |\n",
        "| Miranda Yanglei Pan                     | San Francisco Bay Area           |\n",
        "| Suyang Wang                             | San Francisco Bay Area           |\n",
        "| Eric Tsim, E.I.T.                       | San Francisco Bay Area           |\n",
        "| Daniel Ma                               | San Francisco Bay Area           |\n",
        "| Sidharth Gupta                          | Cambridge, United Kingdom        |\n",
        "| Jody Sheu                               | San Francisco Bay Area           |\n",
        "| Jerry Lee                               | San Francisco Bay Area           |\n",
        "| Uriel Mendoza                           | Greater Los Angeles Area         |\n",
        "| Bo Liao                                 | San Francisco Bay Area           |\n",
        "| Tor Schoenmeyr                          | San Francisco Bay Area           |\n",
        "| Courtney Chandler                       | San Francisco Bay Area           |\n",
        "| Yee Jie Tang                            | Malaysia                         |\n",
        "| Kate Foley                              | Greater New York City Area       |\n",
        "| Cecilia Yu Chung Chang                  | Korea                            |\n",
        "| Gefflin Fu, CPA                         | San Francisco Bay Area           |\n",
        "| Neil Kumar                              | San Francisco Bay Area           |\n",
        "| Freeden Oeur                            | Greater Boston Area              |\n",
        "| Michael Lugo                            | Greater Atlanta Area             |\n",
        "| Jennifer Hom                            | San Francisco Bay Area           |\n",
        "| Susan Ruan                              | San Francisco Bay Area           |\n",
        "| Amy Tang                                | Las Vegas, Nevada Area           |\n",
        "| Kareem Ascha                            | San Francisco Bay Area           |\n",
        "| Joseph Tsay                             | San Francisco Bay Area           |\n",
        "| Jennifer Chen                           | San Francisco Bay Area           |\n",
        "| Connie Phu                              | Greater Los Angeles Area         |\n",
        "| Lindsey Tee                             | Greater Los Angeles Area         |\n",
        "| Debbie Chew                             | Taiwan                           |\n",
        "| Michael Goico                           | San Francisco Bay Area           |\n",
        "| Patty Liu                               | Rochester, Minnesota Area        |\n",
        "| XiaoAn(Sarah) Wang                      | San Francisco Bay Area           |\n",
        "| Dennis Wai                              | San Francisco Bay Area           |\n",
        "| Emily Van Rheenen                       | San Francisco Bay Area           |\n",
        "| Rachel Kang                             | San Francisco Bay Area           |\n",
        "| Mable Huang                             | San Francisco Bay Area           |\n",
        "| Jonathan Yorde                          | Greater Los Angeles Area         |\n",
        "| Leo Wong                                | San Francisco Bay Area           |\n",
        "| Jeff Harter                             | San Francisco Bay Area           |\n",
        "| Regan Smurthwaite                       | San Francisco Bay Area           |\n",
        "| Tiffany Pong, EIT                       | San Francisco Bay Area           |\n",
        "| Janaki Gunnam                           | San Francisco Bay Area           |\n",
        "| Carmen Ren                              | Greater New York City Area       |\n",
        "| Moe Yoshioka                            | San Francisco Bay Area           |\n",
        "| Wendy Li                                | Greater San Diego Area           |\n",
        "| Samuel Lauda                            | San Francisco Bay Area           |\n",
        "| Xiangjiu Wang                           | San Francisco Bay Area           |\n",
        "| Naomi Amakawa                           | San Francisco Bay Area           |\n",
        "| Christian Ting                          | San Francisco Bay Area           |\n",
        "| Francis Chen                            | San Francisco Bay Area           |\n",
        "| Steven Wu                               | San Francisco Bay Area           |\n",
        "| Maritess Aristorenas                    | Greater Los Angeles Area         |\n",
        "| Marissa Teitelman                       | San Francisco Bay Area           |\n",
        "| Jenny Tang                              | San Francisco Bay Area           |\n",
        "| William Tran                            | San Francisco Bay Area           |\n",
        "| Lauren DeWitt                           | San Francisco Bay Area           |\n",
        "| Michael Murata                          | Orange County, California Area   |\n",
        "| Michelle Wong                           | San Francisco Bay Area           |\n",
        "| Eva Pong, EIT                           | San Francisco Bay Area           |\n",
        "| Becky Mar                               | San Francisco Bay Area           |\n",
        "| Jimmy Chen                              | San Francisco Bay Area           |\n",
        "| Anh Bui                                 | Greater San Diego Area           |\n",
        "| Daniel Chatman                          | San Francisco Bay Area           |\n",
        "| Sherry Lee                              | San Francisco Bay Area           |\n",
        "| Ryan Russell                            | San Francisco Bay Area           |\n",
        "| Colin Chang                             | Greater Seattle Area             |\n",
        "| Tiffany Chiao                           | San Francisco Bay Area           |\n",
        "| Noman Paya                              | Greater Chicago Area             |\n",
        "| Aileen Ma                               | San Francisco Bay Area           |\n",
        "| Jamie Lee (\uc774\uc131\uc740)                      | Korea                            |\n",
        "| Elizabeth Sur                           | San Francisco Bay Area           |\n",
        "| Yammy Kung                              | San Francisco Bay Area           |\n",
        "| Melissa Jeng                            | Orange County, California Area   |\n",
        "| Taewon Timothy Jung                     | San Francisco Bay Area           |\n",
        "| Michael McDowell                        | San Francisco Bay Area           |\n",
        "| Gennifer Rose                           | San Francisco Bay Area           |\n",
        "| Henry Chen                              | San Francisco Bay Area           |\n",
        "| Yuta Labur                              | San Francisco Bay Area           |\n",
        "| Len Bargellini                          | San Francisco Bay Area           |\n",
        "| Natalie Friess                          | Toledo, Ohio Area                |\n",
        "| Mark Lee                                | San Francisco Bay Area           |\n",
        "| Paul Huang                              | Austin, Texas Area               |\n",
        "| Lisa Hoover                             | San Francisco Bay Area           |\n",
        "| Brian Liang                             | San Francisco Bay Area           |\n",
        "| Darren Chan                             | San Francisco Bay Area           |\n",
        "| Jessica Gross                           | San Francisco Bay Area           |\n",
        "| Shelanda Adams                          | San Francisco Bay Area           |\n",
        "| Bill Hiddleson                          | San Francisco Bay Area           |\n",
        "| Charlie Nguyen                          | San Francisco Bay Area           |\n",
        "| Sheldon Cheng                           | San Francisco Bay Area           |\n",
        "| Charlie Wong                            | San Francisco Bay Area           |\n",
        "| Justin Telmo                            | San Francisco Bay Area           |\n",
        "| Benfie Liu                              | San Francisco Bay Area           |\n",
        "| Richard Hai                             | San Francisco Bay Area           |\n",
        "| Ashley Gau                              | San Francisco Bay Area           |\n",
        "| Kevin Liang                             | San Francisco Bay Area           |\n",
        "| Rosa Ma                                 | San Francisco Bay Area           |\n",
        "| Jeanie Lyn Arciaga                      | Greater San Diego Area           |\n",
        "| Yeqing (Ching-Ching) Liu                | San Francisco Bay Area           |\n",
        "| Bethany Johnson                         | San Francisco Bay Area           |\n",
        "| Jonathan Lee                            | San Francisco Bay Area           |\n",
        "| Thuan Du                                | San Francisco Bay Area           |\n",
        "| Jonathan Gu                             | Greater Boston Area              |\n",
        "| Cecilia Tong, O.D.                      | San Francisco Bay Area           |\n",
        "| Jenny Tran                              | San Francisco Bay Area           |\n",
        "| Eleana Chiang                           | San Francisco Bay Area           |\n",
        "| Adria Moss                              | San Francisco Bay Area           |\n",
        "| Daniel Chao                             | San Francisco Bay Area           |\n",
        "| Winnie Ip                               | Sacramento, California Area      |\n",
        "| Eric Ren                                | San Francisco Bay Area           |\n",
        "| Kevin Chuc                              | San Francisco Bay Area           |\n",
        "| Anh Mai                                 | San Francisco Bay Area           |\n",
        "| David Su                                | San Francisco Bay Area           |\n",
        "| Jonas Gaardbo Andersen                  | Korea                            |\n",
        "| Vincent Liu                             | San Francisco Bay Area           |\n",
        "| Barbara Kleinhans                       | San Francisco Bay Area           |\n",
        "| Jonathan Kawasaki                       | San Francisco Bay Area           |\n",
        "| Vineet Baid                             | San Francisco Bay Area           |\n",
        "| Leah Hokanson                           | Baltimore, Maryland Area         |\n",
        "| Xiaohan Zhang                           | San Francisco Bay Area           |\n",
        "| Jana Hopkins                            | Greater Los Angeles Area         |\n",
        "| Nghiep Lien                             | San Francisco Bay Area           |\n",
        "| Megumi Ishioka                          | San Francisco Bay Area           |\n",
        "| Clare Tong                              | San Francisco Bay Area           |\n",
        "| Jessica Ju                              | San Francisco Bay Area           |\n",
        "| Zoey Sun                                | Korea                            |\n",
        "| Kylie Foo                               | San Francisco Bay Area           |\n",
        "| Karol Gancarz                           | London, United Kingdom           |\n",
        "| Ben Issler                              | Greater Los Angeles Area         |\n",
        "| Kailin Lu                               | San Francisco Bay Area           |\n",
        "| Victoria Kam                            | San Francisco Bay Area           |\n",
        "| Jonathan Lee                            | San Francisco Bay Area           |\n",
        "| Isiah Regacho                           | San Francisco Bay Area           |\n",
        "| Cai Weisi                               | San Francisco Bay Area           |\n",
        "| Jessica Hsu                             | Greater Denver Area              |\n",
        "| Kelly Ngai                              | San Francisco Bay Area           |\n",
        "| Alison Yee                              | San Francisco Bay Area           |\n",
        "| Marco Lau                               | San Francisco Bay Area           |\n",
        "| Andy Yufeng He                          | Madison, Wisconsin Area          |\n",
        "| Jonathan Wong                           | Greater Los Angeles Area         |\n",
        "| Jaimie Park                             | San Francisco Bay Area           |\n",
        "| Thomas Lin                              | Shanghai City, China             |\n",
        "| Jiwon Moon                              | United States                    |\n",
        "| Jimmy Doan                              | San Francisco Bay Area           |\n",
        "| Alexander Ramirez                       | San Francisco Bay Area           |\n",
        "| Jonie Marie Suzuki                      | San Francisco Bay Area           |\n",
        "| BEACN Berkeley                          | San Francisco Bay Area           |\n",
        "| Victor Chen                             | Greater Los Angeles Area         |\n",
        "| Gillian Wang                            | San Francisco Bay Area           |\n",
        "| Ann Suh                                 | Greater Los Angeles Area         |\n",
        "| Luis Gaemperle                          | Basel Area, Switzerland          |\n",
        "| Enoch Sim                               | Korea                            |\n",
        "| Saya Wai                                | Greater Los Angeles Area         |\n",
        "| Noboru Emori                            | San Francisco Bay Area           |\n",
        "| Jimmy Chung                             | San Francisco Bay Area           |\n",
        "| Alvina Cheung                           | San Francisco Bay Area           |\n",
        "| Nikola Spasojevic                       | London, United Kingdom           |\n",
        "| Yui Kitamura                            | Kawasaki, Kanagawa, Japan        |\n",
        "| Alexandra Bowman                        | San Francisco Bay Area           |\n",
        "| Tonny Leao                              | San Francisco Bay Area           |\n",
        "| Isaac Long                              | San Francisco Bay Area           |\n",
        "| Kitty Su                                | San Francisco Bay Area           |\n",
        "| Edward Kuang                            | San Francisco Bay Area           |\n",
        "| Jacky Leung                             | San Luis Obispo, California Area |\n",
        "| Rocky Zheng                             | San Luis Obispo, California Area |\n",
        "| Zhewen(Wendy) Hu                        | Hangzhou, Zhejiang, China        |\n",
        "| John Wheatley                           | Colchester, United Kingdom       |\n",
        "| Ding Deng                               | Korea                            |\n",
        "+-----------------------------------------+----------------------------------+\n"
       ]
      }
     ],
     "prompt_number": 48
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pt = PrettyTable(field_names=['Industry', 'Frequency'])\n",
      "pt.align = 'l'\n",
      "\n",
      "industry = [c['industry'] for c in connections['values'] if c.has_key('industry')]\n",
      "\n",
      "#for c in connections['values']:\n",
      "#    if c.has_key('industry'):\n",
      "#        print c['industry']\n",
      "\n",
      "c= Counter(industry)\n",
      "[pt.add_row([title, freq]) \n",
      " for (title, freq) in sorted(c.items(), key=itemgetter(1), reverse=True) \n",
      "     if freq > 1]\n",
      "print pt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Example 4. Displaying job position history for your profile and a connection's profile"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import json\n",
      "\n",
      "# See http://developer.linkedin.com/documents/profile-fields#fullprofile\n",
      "# for details on additional field selectors that can be passed in for\n",
      "# retrieving additional profile information.\n",
      "\n",
      "# Display your own positions...\n",
      "\n",
      "my_positions = app.get_profile(selectors=['positions'])\n",
      "print json.dumps(my_positions, indent=1)\n",
      "\n",
      "# Display positions for someone in your network...\n",
      "\n",
      "# Get an id for a connection. We'll just pick the first one.\n",
      "connection_id = connections['values'][0]['id']\n",
      "connection_positions = app.get_profile(member_id=connection_id, \n",
      "                                       selectors=['positions'])\n",
      "print json.dumps(connection_positions, indent=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{\n",
        " \"positions\": {\n",
        "  \"_total\": 6, \n",
        "  \"values\": [\n",
        "   {\n",
        "    \"startDate\": {\n",
        "     \"year\": 2014\n",
        "    }, \n",
        "    \"company\": {\n",
        "     \"id\": 1753, \n",
        "     \"name\": \"Samsung Electronics\"\n",
        "    }, \n",
        "    \"id\": 545269937, \n",
        "    \"isCurrent\": true, \n",
        "    \"title\": \"Strategic Product Marketing Associate\"\n",
        "   }, \n",
        "   {\n",
        "    \"startDate\": {\n",
        "     \"year\": 2013\n",
        "    }, \n",
        "    \"endDate\": {\n",
        "     \"year\": 2013\n",
        "    }, \n",
        "    \"title\": \"Business Analytics\", \n",
        "    \"company\": {\n",
        "     \"id\": 1753, \n",
        "     \"name\": \"Samsung Electronics\"\n",
        "    }, \n",
        "    \"summary\": \"Worked on forecast modeling research (including big data analysis) and data organization in a SQL/Python environment\\n\\n- Created SQL server database for department sales data and pushed data preparation, scoring\\nand reporting services to db level\\n- Used time series and Bayesian forecasting techniques in Python analysis environment to develop\\nrobust forecast model. Connected model to the production data warehouse\\n- Advised VP and SVP on relevant statistical trends in the forecast model and user data\", \n",
        "    \"isCurrent\": false, \n",
        "    \"id\": 424879779\n",
        "   }, \n",
        "   {\n",
        "    \"startDate\": {\n",
        "     \"year\": 2012\n",
        "    }, \n",
        "    \"endDate\": {\n",
        "     \"year\": 2012\n",
        "    }, \n",
        "    \"title\": \"Supply Planning Reporting\", \n",
        "    \"company\": {\n",
        "     \"id\": 3137, \n",
        "     \"name\": \"Levi Strauss & Co.\"\n",
        "    }, \n",
        "    \"summary\": \"\\u2022\\tOptimized global process workflow by writing VBA code into existing Excel infrastructure to create new user-friendly software for use by the supply planning team- new processes reduced labor by over 15 hours a month \\n\\u2022\\tDesigned database in Access to match regional SAP purchase data with global purchase order confirmations and compiled information into a simple new monthly report\\n\\u2022\\tPresented online group buying proposal to CEO and Brand President and provided project insights from supply chain perspective  \\n\\u2022\\tManaged cross-functional team of interns in planning Dockers marketing campaign targeted towards \\u201cMillennial Status Seekers\\u201d\", \n",
        "    \"isCurrent\": false, \n",
        "    \"id\": 308089962\n",
        "   }, \n",
        "   {\n",
        "    \"startDate\": {\n",
        "     \"year\": 2010\n",
        "    }, \n",
        "    \"endDate\": {\n",
        "     \"year\": 2012\n",
        "    }, \n",
        "    \"title\": \"Program Assistant\", \n",
        "    \"company\": {\n",
        "     \"name\": \"Haas School of Business Evening and Weekend MBA\"\n",
        "    }, \n",
        "    \"summary\": \"\\u2022\\tOrganized admissions events including information sessions and admit receptions with hundreds of attendees \\n\\u2022\\tMaintained databases and records of over 4000 applicants using Microsoft Access and Excel\\n\\u2022\\tCorrespond with applicants to ensure smooth application processing\", \n",
        "    \"isCurrent\": false, \n",
        "    \"id\": 242913956\n",
        "   }, \n",
        "   {\n",
        "    \"startDate\": {\n",
        "     \"year\": 2010\n",
        "    }, \n",
        "    \"endDate\": {\n",
        "     \"year\": 2010\n",
        "    }, \n",
        "    \"title\": \"Business Development\", \n",
        "    \"company\": {\n",
        "     \"id\": 941674, \n",
        "     \"name\": \"zozi\"\n",
        "    }, \n",
        "    \"summary\": \"-Researched companies in the tourism industry located in Orange County and Nashville markets\\n-Engaged in sales activities to over 300 potential partners and maintained direct relationships with over 25 clients eventually leading to 16 new partnerships for the company\", \n",
        "    \"isCurrent\": false, \n",
        "    \"id\": 242904938\n",
        "   }, \n",
        "   {\n",
        "    \"startDate\": {\n",
        "     \"year\": 2005\n",
        "    }, \n",
        "    \"endDate\": {\n",
        "     \"year\": 2009\n",
        "    }, \n",
        "    \"title\": \"Intern\", \n",
        "    \"company\": {\n",
        "     \"id\": 46308, \n",
        "     \"name\": \"Chabot Space & Science Center\"\n",
        "    }, \n",
        "    \"isCurrent\": false, \n",
        "    \"id\": 242912731\n",
        "   }\n",
        "  ]\n",
        " }\n",
        "}\n",
        "{\n",
        " \"positions\": {\n",
        "  \"_total\": 1, \n",
        "  \"values\": [\n",
        "   {\n",
        "    \"startDate\": {\n",
        "     \"year\": 2014, \n",
        "     \"month\": 3\n",
        "    }, \n",
        "    \"title\": \"Global Executive Recruiter, eCommerce & Finance Account Manager\", \n",
        "    \"company\": {\n",
        "     \"name\": \"Levi Strauss & Co.\"\n",
        "    }, \n",
        "    \"summary\": \"Responsible for global executive searches, including key functional, product and geographical hiring at VP and above. Proactively develop strategic talent pipeline for Levi Strauss' mission critical positions.  Recent hires include: Brand Presidents & Chief Marketing Officers, Global SVP of Product Development & Sourcing, Chief Counsel for Asia Pacific Region and CFO, Greater China.  In FY2013, saved LS&Co. over. $.5M+ in global agency fees vua  direct sourcing efforts.\\n\\nMy scope has recently expanded to be the dedicated Account Manager for LS&Co's Global eCommerce team.  A key growth strategy as we transform to a robust omnichannel retailer.  Work directly with President of Global eCommerce.\", \n",
        "    \"isCurrent\": true, \n",
        "    \"id\": 158133910\n",
        "   }\n",
        "  ]\n",
        " }\n",
        "}"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Example 5. Using field selector syntax to request additional details for APIs"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# See http://developer.linkedin.com/documents/understanding-field-selectors\n",
      "# for more information on the field selector syntax\n",
      "\n",
      "my_positions = app.get_profile(selectors=['positions:(company:(name,industry,id))'])\n",
      "print json.dumps(my_positions, indent=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{\n",
        " \"positions\": {\n",
        "  \"_total\": 6, \n",
        "  \"values\": [\n",
        "   {\n",
        "    \"company\": {\n",
        "     \"industry\": \"Consumer Electronics\", \n",
        "     \"id\": 1753, \n",
        "     \"name\": \"Samsung Electronics\"\n",
        "    }\n",
        "   }, \n",
        "   {\n",
        "    \"company\": {\n",
        "     \"industry\": \"Consumer Electronics\", \n",
        "     \"id\": 1753, \n",
        "     \"name\": \"Samsung Electronics\"\n",
        "    }\n",
        "   }, \n",
        "   {\n",
        "    \"company\": {\n",
        "     \"industry\": \"Apparel & Fashion\", \n",
        "     \"id\": 3137, \n",
        "     \"name\": \"Levi Strauss & Co.\"\n",
        "    }\n",
        "   }, \n",
        "   {\n",
        "    \"company\": {\n",
        "     \"industry\": \"Market Research\", \n",
        "     \"name\": \"Haas School of Business Evening and Weekend MBA\"\n",
        "    }\n",
        "   }, \n",
        "   {\n",
        "    \"company\": {\n",
        "     \"industry\": \"Leisure, Travel & Tourism\", \n",
        "     \"id\": 941674, \n",
        "     \"name\": \"zozi\"\n",
        "    }\n",
        "   }, \n",
        "   {\n",
        "    \"company\": {\n",
        "     \"industry\": \"Museums and Institutions\", \n",
        "     \"id\": 46308, \n",
        "     \"name\": \"Chabot Space & Science Center\"\n",
        "    }\n",
        "   }\n",
        "  ]\n",
        " }\n",
        "}\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Example 6. Simple normalization of company suffixes from address book data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "import csv\n",
      "from collections import Counter\n",
      "from operator import itemgetter\n",
      "from prettytable import PrettyTable\n",
      "\n",
      "# XXX: Place your \"Outlook CSV\" formatted file of connections from \n",
      "# http://www.linkedin.com/people/export-settings at the following\n",
      "# location: resources/ch03-linkedin/my_connections.csv\n",
      "\n",
      "CSV_FILE = os.path.join(\"resources\", \"ch03-linkedin\", 'my_connections.csv')\n",
      "\n",
      "# Define a set of transforms that converts the first item\n",
      "# to the second item. Here, we're simply handling some\n",
      "# commonly known abbreviations, stripping off common suffixes, \n",
      "# etc.\n",
      "\n",
      "transforms = [(', Inc.', ''), (', Inc', ''), (', LLC', ''), (', LLP', ''),\n",
      "               (' LLC', ''), (' Inc.', ''), (' Inc', '')]\n",
      "\n",
      "csvReader = csv.DictReader(open(CSV_FILE), delimiter=',', quotechar='\"')\n",
      "contacts = [row for row in csvReader]\n",
      "companies = [c['Company'].strip() for c in contacts if c['Company'].strip() != '']\n",
      "\n",
      "for i, _ in enumerate(companies):\n",
      "    for transform in transforms:\n",
      "        companies[i] = companies[i].replace(*transform)\n",
      "\n",
      "pt = PrettyTable(field_names=['Company', 'Freq'])\n",
      "pt.align = 'l'\n",
      "c = Counter(companies)\n",
      "[pt.add_row([company, freq]) \n",
      " for (company, freq) in sorted(c.items(), key=itemgetter(1), reverse=True) \n",
      "     if freq > 1]\n",
      "print pt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "+---------------------+------+\n",
        "| Company             | Freq |\n",
        "+---------------------+------+\n",
        "| Levi Strauss & Co.  | 11   |\n",
        "| Samsung Electronics | 8    |\n",
        "| UC Berkeley         | 4    |\n",
        "| EY                  | 3    |\n",
        "| Tesla Motors        | 3    |\n",
        "| Accenture           | 2    |\n",
        "| Flipboard           | 2    |\n",
        "| Microsoft           | 2    |\n",
        "| Adap.tv             | 2    |\n",
        "| LinkedIn            | 2    |\n",
        "| Benefit Cosmetics   | 2    |\n",
        "| Apple               | 2    |\n",
        "+---------------------+------+\n"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Example 7. Standardizing common job titles and computing their frequencies"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "import csv\n",
      "from operator import itemgetter\n",
      "from collections import Counter\n",
      "from prettytable import PrettyTable\n",
      "\n",
      "# XXX: Place your \"Outlook CSV\" formatted file of connections from \n",
      "# http://www.linkedin.com/people/export-settings at the following\n",
      "# location: resources/ch03-linkedin/my_connections.csv\n",
      "\n",
      "CSV_FILE = os.path.join(\"resources\", \"ch03-linkedin\", 'my_connections.csv')\n",
      "\n",
      "transforms = [\n",
      "    ('Sr.', 'Senior'),\n",
      "    ('Sr', 'Senior'),\n",
      "    ('Jr.', 'Junior'),\n",
      "    ('Jr', 'Junior'),\n",
      "    ('CEO', 'Chief Executive Officer'),\n",
      "    ('COO', 'Chief Operating Officer'),\n",
      "    ('CTO', 'Chief Technology Officer'),\n",
      "    ('CFO', 'Chief Finance Officer'),\n",
      "    ('VP', 'Vice President'),\n",
      "    ]\n",
      "\n",
      "csvReader = csv.DictReader(open(CSV_FILE), delimiter=',', quotechar='\"')\n",
      "contacts = [row for row in csvReader]\n",
      "\n",
      "# Read in a list of titles and split apart\n",
      "# any combined titles like \"President/CEO.\"\n",
      "# Other variations could be handled as well, such\n",
      "# as \"President & CEO\", \"President and CEO\", etc.\n",
      "\n",
      "titles = []\n",
      "for contact in contacts:\n",
      "    titles.extend([t.strip() for t in contact['Job Title'].split('/')\n",
      "                  if contact['Job Title'].strip() != ''])\n",
      "\n",
      "# Replace common/known abbreviations\n",
      "\n",
      "for i, _ in enumerate(titles):\n",
      "    for transform in transforms:\n",
      "        titles[i] = titles[i].replace(*transform)\n",
      "\n",
      "# Print out a table of titles sorted by frequency\n",
      "\n",
      "pt = PrettyTable(field_names=['Title', 'Freq'])\n",
      "pt.align = 'l'\n",
      "c = Counter(titles)\n",
      "[pt.add_row([title, freq]) \n",
      " for (title, freq) in sorted(c.items(), key=itemgetter(1), reverse=True) \n",
      "     if freq > 1]\n",
      "print pt\n",
      "\n",
      "# Print out a table of tokens sorted by frequency\n",
      "\n",
      "tokens = []\n",
      "for title in titles:\n",
      "    tokens.extend([t.strip(',') for t in title.split()])\n",
      "pt = PrettyTable(field_names=['Token', 'Freq'])\n",
      "pt.align = 'l'\n",
      "c = Counter(tokens)\n",
      "[pt.add_row([token, freq]) \n",
      " for (token, freq) in sorted(c.items(), key=itemgetter(1), reverse=True) \n",
      "     if freq > 1 and len(token) > 2]\n",
      "print pt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "+---------------------------------------+------+\n",
        "| Title                                 | Freq |\n",
        "+---------------------------------------+------+\n",
        "| Research Assistant                    | 4    |\n",
        "| Founder                               | 3    |\n",
        "| Associate                             | 3    |\n",
        "| Marketing Coordinator                 | 3    |\n",
        "| Teaching Assistant                    | 2    |\n",
        "| Chief Executive Officer               | 2    |\n",
        "| Undergraduate Researcher              | 2    |\n",
        "| Financial Analyst                     | 2    |\n",
        "| Owner                                 | 2    |\n",
        "| Software Engineer                     | 2    |\n",
        "| Investment Banking Analyst            | 2    |\n",
        "| Administrative Assistant              | 2    |\n",
        "| Executive Director                    | 2    |\n",
        "| Consultant                            | 2    |\n",
        "| Manager                               | 2    |\n",
        "| President and Chief Executive Officer | 2    |\n",
        "| Project Engineer                      | 2    |\n",
        "+---------------------------------------+------+\n",
        "+----------------+------+\n",
        "| Token          | Freq |\n",
        "+----------------+------+\n",
        "| Manager        | 24   |\n",
        "| Assistant      | 19   |\n",
        "| and            | 18   |\n",
        "| Engineer       | 17   |\n",
        "| Associate      | 17   |\n",
        "| Analyst        | 16   |\n",
        "| Intern         | 14   |\n",
        "| Global         | 13   |\n",
        "| Business       | 12   |\n",
        "| Director       | 12   |\n",
        "| Senior         | 11   |\n",
        "| Research       | 11   |\n",
        "| Coordinator    | 11   |\n",
        "| Development    | 11   |\n",
        "| Marketing      | 11   |\n",
        "| Operations     | 9    |\n",
        "| President      | 9    |\n",
        "| Executive      | 9    |\n",
        "| Product        | 8    |\n",
        "| Software       | 7    |\n",
        "| Supply         | 7    |\n",
        "| Account        | 6    |\n",
        "| Project        | 6    |\n",
        "| Strategy       | 6    |\n",
        "| Officer        | 5    |\n",
        "| Planning       | 5    |\n",
        "| Sales          | 5    |\n",
        "| Consultant     | 5    |\n",
        "| Chief          | 5    |\n",
        "| Service        | 4    |\n",
        "| Recruiter      | 4    |\n",
        "| Volunteer      | 4    |\n",
        "| for            | 4    |\n",
        "| Vice           | 4    |\n",
        "| Researcher     | 4    |\n",
        "| Teacher        | 4    |\n",
        "| Customer       | 4    |\n",
        "| Services       | 3    |\n",
        "| Mobile         | 3    |\n",
        "| Financial      | 3    |\n",
        "| Acquisition    | 3    |\n",
        "| Management     | 3    |\n",
        "| Teaching       | 3    |\n",
        "| Assurance      | 3    |\n",
        "| Samsung        | 3    |\n",
        "| Specialist     | 3    |\n",
        "| Designer       | 3    |\n",
        "| Chain          | 3    |\n",
        "| Investment     | 3    |\n",
        "| Member         | 3    |\n",
        "| Program        | 3    |\n",
        "| Talent         | 3    |\n",
        "| Center         | 3    |\n",
        "| Founder        | 3    |\n",
        "| Recruiting     | 3    |\n",
        "| Administrative | 3    |\n",
        "| Student        | 3    |\n",
        "| Advisor        | 3    |\n",
        "| Staff          | 3    |\n",
        "| Graduate       | 2    |\n",
        "| Systems        | 2    |\n",
        "| Resources      | 2    |\n",
        "| Levi's         | 2    |\n",
        "| Analysis       | 2    |\n",
        "| Legal          | 2    |\n",
        "| Inventory      | 2    |\n",
        "| Material       | 2    |\n",
        "| Representative | 2    |\n",
        "| Computer       | 2    |\n",
        "| Design         | 2    |\n",
        "| Human          | 2    |\n",
        "| Owner          | 2    |\n",
        "| Undergraduate  | 2    |\n",
        "| Developer      | 2    |\n",
        "| Group          | 2    |\n",
        "| Website        | 2    |\n",
        "| Finance        | 2    |\n",
        "| Media          | 2    |\n",
        "| MBA            | 2    |\n",
        "| Search         | 2    |\n",
        "| Banking        | 2    |\n",
        "| Client         | 2    |\n",
        "| Consumer       | 2    |\n",
        "| Advisory       | 2    |\n",
        "| Affairs        | 2    |\n",
        "| Analytics      | 2    |\n",
        "| Scientist      | 2    |\n",
        "| Communications | 2    |\n",
        "| Technology     | 2    |\n",
        "+----------------+------+\n"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Example 8. Geocoding locations with Microsoft Bing"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from geopy import geocoders\n",
      "\n",
      "GEO_APP_KEY = 'AtnzaD1gYk2VwenUlaHFScmD6zXp-zk_fBGJofdZ8oAi1FRbe8jKyipMzHiwhkc7' # XXX: Get this from https://www.bingmapsportal.com\n",
      "g = geocoders.Bing(GEO_APP_KEY)\n",
      "print g.geocode(\"Nashville\", exactly_one=False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[Location(Nashville, TN, United States 36 10m 0.0s N, 86 47m 0.0s W), Location(Nashville, IN, United States 39 13m 0.0s N, 86 15m 0.0s W), Location(Nashville, IL, United States 38 21m 0.0s N, 89 23m 0.0s W), Location(Nashville, AR, United States 33 57m 0.0s N, 93 51m 0.0s W), Location(Nashville, NC, United States 35 58m 0.0s N, 77 58m 0.0s W)]\n"
       ]
      }
     ],
     "prompt_number": 57
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Example 9. Geocoding locations of LinkedIn connections with Microsoft Bing"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from geopy import geocoders\n",
      "\n",
      "GEO_APP_KEY = 'AtnzaD1gYk2VwenUlaHFScmD6zXp-zk_fBGJofdZ8oAi1FRbe8jKyipMzHiwhkc7' # XXX: Get this from https://www.bingmapsportal.com\n",
      "g = geocoders.Bing(GEO_APP_KEY)\n",
      "\n",
      "transforms = [('Greater ', ''), (' Area', '')]\n",
      "\n",
      "results = {}\n",
      "for c in connections['values']:\n",
      "    if not c.has_key('location'): continue\n",
      "        \n",
      "    transformed_location = c['location']['name']\n",
      "    for transform in transforms:\n",
      "        transformed_location = transformed_location.replace(*transform)\n",
      "    geo = g.geocode(transformed_location, exactly_one=False)\n",
      "    if geo == []: continue\n",
      "    results.update({ c['location']['name'] : geo })\n",
      "\n",
      "print results    \n",
      "print json.dumps(results, indent=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "GeocoderTimedOut",
       "evalue": "Service timed out",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mGeocoderTimedOut\u001b[0m                          Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-58-768f8ef611db>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mtransform\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0mtransformed_location\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransformed_location\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[0mgeo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgeocode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtransformed_location\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexactly_one\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mgeo\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mcontinue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[0mresults\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'location'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'name'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mgeo\u001b[0m \u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\geopy\\geocoders\\bing.pyc\u001b[0m in \u001b[0;36mgeocode\u001b[1;34m(self, query, exactly_one, user_location, timeout)\u001b[0m\n\u001b[0;32m     87\u001b[0m         \u001b[0murl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"?\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murlencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"%s.geocode: %s\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 89\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parse_json\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_geocoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexactly_one\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     90\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mreverse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mquery\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexactly_one\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m# pylint: disable=W0221\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\geopy\\geocoders\\base.pyc\u001b[0m in \u001b[0;36m_call_geocoder\u001b[1;34m(self, url, timeout, raw)\u001b[0m\n\u001b[0;32m    110\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mURLError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;34m\"timed out\"\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 112\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0mGeocoderTimedOut\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Service timed out'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    113\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSocketTimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mGeocoderTimedOut\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Service timed out'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mGeocoderTimedOut\u001b[0m: Service timed out"
       ]
      }
     ],
     "prompt_number": 58
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Example 10. Parsing out states from Bing geocoder results using a regular expression"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import re\n",
      "\n",
      "# Most results contain a response that can be parsed by\n",
      "# picking out the first two consecutive upper case letters \n",
      "# as a clue for the state\n",
      "pattern = re.compile('.*([A-Z]{2}).*')\n",
      "    \n",
      "def parseStateFromBingResult(r):\n",
      "    result = pattern.search(r[0][0])\n",
      "    if result == None: \n",
      "        print \"Unresolved match:\", r\n",
      "        return \"???\"\n",
      "    elif len(result.groups()) == 1:\n",
      "        print result.groups()\n",
      "        return result.groups()[0]\n",
      "    else:\n",
      "        print \"Unresolved match:\", result.groups()\n",
      "        return \"???\"\n",
      "\n",
      "    \n",
      "transforms = [('Greater ', ''), (' Area', '')]\n",
      "\n",
      "results = {}\n",
      "for c in connections['values']:\n",
      "    if not c.has_key('location'): continue\n",
      "    if not c['location']['country']['code'] == 'us': continue\n",
      "        \n",
      "    transformed_location = c['location']['name']\n",
      "    for transform in transforms:\n",
      "        transformed_location = transformed_location.replace(*transform)\n",
      "    \n",
      "    geo = g.geocode(transformed_location, exactly_one=False)\n",
      "    if geo == []: continue\n",
      "    parsed_state = parseStateFromBingResult(geo)\n",
      "    if parsed_state != \"???\":\n",
      "        results.update({c['location']['name'] : parsed_state})\n",
      "    \n",
      "print json.dumps(results, indent=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(u'CA',)\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'WA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'DC',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'WA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'NY',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'MA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'WA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'NY',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'MA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'GA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'NV',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'MN',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'WA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'NY',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'WA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'IL',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'OH',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'TX',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'DC',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'MA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'MD',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CO',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'WI',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Unresolved match:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [Location(United States 39 27m 0.0s N, 98 57m 0.0s W)]\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Unresolved match:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [Location(United States 39 27m 0.0s N, 98 57m 0.0s W)]\n",
        "(u'CA',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "{\n",
        " \"Greater Seattle Area\": \"WA\", \n",
        " \"Greater Los Angeles Area\": \"CA\", \n",
        " \"Greater New York City Area\": \"NY\", \n",
        " \"San Francisco Bay Area\": \"CA\", \n",
        " \"Orange County, California Area\": \"CA\", \n",
        " \"Madison, Wisconsin Area\": \"WI\", \n",
        " \"Greater Atlanta Area\": \"GA\", \n",
        " \"Sacramento, California Area\": \"CA\", \n",
        " \"Greater Chicago Area\": \"IL\", \n",
        " \"Washington D.C. Metro Area\": \"DC\", \n",
        " \"Austin, Texas Area\": \"TX\", \n",
        " \"Greater Boston Area\": \"MA\", \n",
        " \"Toledo, Ohio Area\": \"OH\", \n",
        " \"Baltimore, Maryland Area\": \"MD\", \n",
        " \"Greater San Diego Area\": \"CA\", \n",
        " \"San Luis Obispo, California Area\": \"CA\", \n",
        " \"Las Vegas, Nevada Area\": \"NV\", \n",
        " \"Greater Denver Area\": \"CO\", \n",
        " \"Rochester, Minnesota Area\": \"MN\"\n",
        "}\n"
       ]
      }
     ],
     "prompt_number": 59
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Here's how to power a Cartogram visualization with the data from the \"results\" variable**"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "import json\n",
      "from IPython.display import IFrame\n",
      "from IPython.core.display import display\n",
      "\n",
      "# Load in a data structure mapping state names to codes.\n",
      "# e.g. West Virginia is WV\n",
      "codes = json.loads(open('resources/ch03-linkedin/viz/states-codes.json').read())\n",
      "\n",
      "from collections import Counter\n",
      "c = Counter([r[1] for r in results.items()])\n",
      "states_freqs = { codes[k] : v for (k,v) in c.items() }\n",
      "\n",
      "# Lace in all of the other states and provide a minimum value for each of them\n",
      "states_freqs.update({v : 0.5 for v in codes.values() if v not in states_freqs.keys() })\n",
      "\n",
      "# Write output to file\n",
      "f = open('resources/ch03-linkedin/viz/states-freqs.json', 'w')\n",
      "f.write(json.dumps(states_freqs, indent=1))\n",
      "f.close()\n",
      "\n",
      "# IPython Notebook can serve files and display them into\n",
      "# inline frames. Prepend the path with the 'files' prefix\n",
      "\n",
      "display(IFrame('files/resources/ch03-linkedin/viz/cartogram.html', '100%', '600px'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "\n",
        "        <iframe\n",
        "            width=\"100%\"\n",
        "            height=600px\"\n",
        "            src=\"files/resources/ch03-linkedin/viz/cartogram.html\"\n",
        "            frameborder=\"0\"\n",
        "            allowfullscreen\n",
        "        ></iframe>\n",
        "        "
       ],
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "<IPython.lib.display.IFrame at 0x5614e80>"
       ]
      }
     ],
     "prompt_number": 60
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Example 11. Using NLTK to compute bigrams"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import nltk\n",
      "ceo_bigrams = nltk.bigrams(\"Chief Executive Officer\".split(), pad_right=True, \n",
      "                                                              pad_left=True)\n",
      "cto_bigrams = nltk.bigrams(\"Chief Technology Officer\".split(), pad_right=True, \n",
      "                                                               pad_left=True)\n",
      "\n",
      "print ceo_bigrams\n",
      "print cto_bigrams\n",
      "print len(set(ceo_bigrams).intersection(set(cto_bigrams)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[(None, 'Chief'), ('Chief', 'Executive'), ('Executive', 'Officer'), ('Officer', None)]\n",
        "[(None, 'Chief'), ('Chief', 'Technology'), ('Technology', 'Officer'), ('Officer', None)]\n",
        "2\n"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Example 12. Clustering job titles using a greedy heuristic"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import csv\n",
      "from nltk.metrics.distance import jaccard_distance\n",
      "\n",
      "# XXX: Place your \"Outlook CSV\" formatted file of connections from \n",
      "# http://www.linkedin.com/people/export-settings at the following\n",
      "# location: resources/ch03-linkedin/my_connections.csv\n",
      "\n",
      "CSV_FILE = os.path.join(\"resources\", \"ch03-linkedin\", 'my_connections.csv')\n",
      "\n",
      "# Tweak this distance threshold and try different distance calculations \n",
      "# during experimentation\n",
      "DISTANCE_THRESHOLD = 0.5\n",
      "DISTANCE = jaccard_distance\n",
      "\n",
      "csvReader = csv.DictReader(open(CSV_FILE), delimiter=',', quotechar='\"')\n",
      "contacts = [row for row in csvReader]\n",
      "\n",
      "print enumerate(contacts)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "<enumerate object at 0x0000000013C402D0>\n"
       ]
      }
     ],
     "prompt_number": 81
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "import csv\n",
      "from nltk.metrics.distance import jaccard_distance\n",
      "\n",
      "# XXX: Place your \"Outlook CSV\" formatted file of connections from \n",
      "# http://www.linkedin.com/people/export-settings at the following\n",
      "# location: resources/ch03-linkedin/my_connections.csv\n",
      "\n",
      "CSV_FILE = os.path.join(\"resources\", \"ch03-linkedin\", 'my_connections.csv')\n",
      "\n",
      "# Tweak this distance threshold and try different distance calculations \n",
      "# during experimentation\n",
      "DISTANCE_THRESHOLD = 0.6\n",
      "DISTANCE = jaccard_distance\n",
      "\n",
      "def cluster_contacts_by_title(csv_file):\n",
      "\n",
      "    transforms = [\n",
      "        ('Sr.', 'Senior'),\n",
      "        ('Sr', 'Senior'),\n",
      "        ('Jr.', 'Junior'),\n",
      "        ('Jr', 'Junior'),\n",
      "        ('CEO', 'Chief Executive Officer'),\n",
      "        ('COO', 'Chief Operating Officer'),\n",
      "        ('CTO', 'Chief Technology Officer'),\n",
      "        ('CFO', 'Chief Finance Officer'),\n",
      "        ('VP', 'Vice President'),\n",
      "        ]\n",
      "\n",
      "    separators = ['/', ' and ', '&']\n",
      "\n",
      "    csvReader = csv.DictReader(open(csv_file), delimiter=',', quotechar='\"')\n",
      "    contacts = [row for row in csvReader]\n",
      "\n",
      "    # Normalize and/or replace known abbreviations\n",
      "    # and build up a list of common titles.\n",
      "\n",
      "    all_titles = []\n",
      "    for i, _ in enumerate(contacts):\n",
      "        if contacts[i]['Job Title'] == '':\n",
      "            contacts[i]['Job Titles'] = ['']\n",
      "            continue\n",
      "        titles = [contacts[i]['Job Title'].strip()]\n",
      "        for title in titles:\n",
      "            for separator in separators:\n",
      "                if title.find(separator) >= 0:\n",
      "                    titles.remove(title.strip())\n",
      "                    titles.extend([title.strip() for title in title.split(separator)\n",
      "                                  if title.strip() != ''])\n",
      "\n",
      "        for transform in transforms:\n",
      "            titles = [title.replace(*transform) for title in titles]\n",
      "        contacts[i]['Job Titles'] = titles\n",
      "        all_titles.extend(titles)\n",
      "\n",
      "    all_titles = list(set(all_titles))\n",
      "\n",
      "    clusters = {}\n",
      "    for title1 in all_titles:\n",
      "        clusters[title1] = []\n",
      "        for title2 in all_titles:\n",
      "            if title2 in clusters[title1] or clusters.has_key(title2) and title1 \\\n",
      "                in clusters[title2]:\n",
      "                continue\n",
      "            distance = DISTANCE(set(title1.split()), set(title2.split()))\n",
      "\n",
      "            if distance < DISTANCE_THRESHOLD:\n",
      "                clusters[title1].append(title2)\n",
      "\n",
      "    # Flatten out clusters\n",
      "\n",
      "    clusters = [clusters[title] for title in clusters if len(clusters[title]) > 1]\n",
      "\n",
      "    # Round up contacts who are in these clusters and group them together\n",
      "\n",
      "    clustered_contacts = {}\n",
      "    for cluster in clusters:\n",
      "        clustered_contacts[tuple(cluster)] = []\n",
      "        for contact in contacts:\n",
      "            for title in contact['Job Titles']:\n",
      "                if title in cluster:\n",
      "                    clustered_contacts[tuple(cluster)].append('%s %s'\n",
      "                            % (contact['First Name'], contact['Last Name']))\n",
      "\n",
      "    return clustered_contacts\n",
      "\n",
      "\n",
      "clustered_contacts = cluster_contacts_by_title(CSV_FILE)\n",
      "print clustered_contacts\n",
      "for titles in clustered_contacts:\n",
      "    common_titles_heading = 'Common Titles: ' + ', '.join(titles)\n",
      "\n",
      "    descriptive_terms = set(titles[0].split())\n",
      "    for title in titles:\n",
      "        descriptive_terms.intersection_update(set(title.split()))\n",
      "    descriptive_terms_heading = 'Descriptive Terms: ' \\\n",
      "        + ', '.join(descriptive_terms)\n",
      "    print descriptive_terms_heading\n",
      "    print '-' * max(len(descriptive_terms_heading), len(common_titles_heading))\n",
      "    print '\\n'.join(clustered_contacts[titles])\n",
      "    print"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{('Management Consultant', 'Consultant'): ['Jay Tong', 'Janaki Gunnam', 'Jeff Harter'], ('Case Manager', 'Manager'): ['Hyunhee (Ryan) Cho', 'Thomas Lin', 'Jenny Tran'], ('EVice President', 'President'): ['James Curleigh', 'Larry Maye', 'Gillian Wang', 'Chip Bergh'], ('Software Engineer', 'Associate Software Engineer'): ['Anh Mai', 'Howard Haotian Bai', 'Omar Rehmane'], ('Associate', 'Marketing Associate'): ['Jonas Andersen', 'Cathy Hwang', 'Cecilia Yu Chung Chang', 'Phi Nguyen'], ('Assistant Language Teacher', 'Teacher Assistant'): ['Wendy Li', 'Jana Hopkins'], ('Analysis', 'Analysis Intern'): ['Winnie Ip', 'Michael Goico'], ('Customer Service Representative', 'Customer Service Associate'): ['Yammy Kung', 'Debbie Chew'], ('Marketing', 'Marketing Coordinator', 'Marketing Director', 'Marketing Associate'): ['Connie Phu', 'Elizabeth Sur', 'Summer Sang-a Kim', 'Kylie Foo', 'Phi Nguyen', 'Tiffany Chiao'], ('House Manager', 'Manager'): ['Hyunhee (Ryan) Cho', 'Jonathan Lee', 'Thomas Lin'], ('Operations', 'Revenue Operations', 'Operations Intern'): ['Brian Fukumoto', 'Dawn Miedler', 'Justin Yu', 'Zhewen(Wendy) Hu'], ('Business Operations Manager, Worldwide Sales Group, Legal', 'Manager, Business Operations'): ['Molly Amble Kihanya', 'John Holgate'], ('Product Marketing', 'Marketing'): ['Deanne Chen', 'Tiffany Chiao'], ('Teacher', 'Teacher Assistant'): ['Wendy Li', 'Bill Hiddleson'], ('Business Operations Analyst', 'Business Technology Analyst', 'Manager, Business Operations'): ['Deidre Quan', 'John Holgate', 'Simon Tiu'], ('Business Analyst', 'Business Operations Analyst', 'Business Technology Analyst'): ['Deidre Quan', 'Sylvia Tang', 'Simon Tiu'], ('Designer', 'Independent Designer', 'Graphic Designer'): ['Darren Chan', 'Francis Chen', 'Jessica Gross'], ('Sales Associate', 'Associate'): ['Alexander Ramirez', 'Jonas Andersen', 'Cathy Hwang', 'Cecilia Yu Chung Chang'], ('Website Director', 'Director'): ['David Su', 'Clare Tong'], ('Graduate Student Researcher', 'Graduate Student Intern'): ['Dennis Wai', 'Alan Huynh'], ('Analyst', 'Business Analyst', 'Project Analyst', 'Financial Analyst'): ['Vineet Baid', 'Leo Wong', 'Devon Jue', 'Sylvia Tang', 'Jenny Jiang'], ('Product Development', 'Project Manager, Product Development'): ['Tim McAtee', 'Bethany Johnson'], ('Research', 'Research Assistant'): ['Cheng Lu', 'Rosa Ma', 'Winnie Ip', 'Xiangjiu Wang', 'Jonathan Wong', 'Candace Wong-Sing'], ('Project Manager', 'Manager'): ['Hyunhee (Ryan) Cho', 'Thomas Lin', 'Yeqing (Ching-Ching) Liu'], ('Assurance Associate', 'Associate Quality Assurance Engineer', 'Associate'): ['Miranda Yanglei Pan', 'Jonas Andersen', 'Cathy Hwang', 'Jennifer Chen', 'Cecilia Yu Chung Chang'], ('Production Manager', 'Manager'): ['Hyunhee (Ryan) Cho', 'Charlie Nguyen', 'Thomas Lin'], ('DC Manager', 'Manager'): ['Hyunhee (Ryan) Cho', 'Henry Chen', 'Thomas Lin'], ('Finance Associate', 'Associate'): ['Jessica Lukrich', 'Jonas Andersen', 'Cathy Hwang', 'Cecilia Yu Chung Chang'], ('SpareOne Product Management', 'RDP Product Management'): ['George Nguyen', 'Phi Nguyen'], ('Recruiter', 'Healthcare Recruiter'): ['Susan Ruan', 'Christian Bada'], ('Chief Executive Officer', 'Chief Operating Officer'): ['Ric Kostick', 'Marissa Teitelman', 'Len Bargellini', 'Larry Maye', 'Chip Bergh'], ('Marketing Intern', 'Marketing'): ['George Nguyen', 'Tiffany Chiao'], ('Investment Banking Analyst', 'Senior Investment Analyst'): ['Kobe Li', 'Frances Bo', 'Daniel Ma'], ('Director', 'Executive Director', 'Marketing Director'): ['Marjorie DeGraca', 'Kylie Foo', 'Clare Tong', 'Jesse Krieger'], ('Portfolio Manager', 'Manager'): ['Hyunhee (Ryan) Cho', 'Charlie Wong', 'Thomas Lin'], ('Search Account Associate', 'Associate Account Executive'): ['Ryan Shi', 'Jenny Tang'], ('Undergraduate Researcher', 'Researcher'): ['Edward Kuang', 'Kareem Ascha', 'Jonathan Gu'], ('Specialty Associate', 'Associate'): ['Jonas Andersen', 'Kevin Chuc', 'Cathy Hwang', 'Cecilia Yu Chung Chang']}\n",
        "Descriptive Terms: Consultant\n",
        "------------------------------------------------\n",
        "Jay Tong\n",
        "Janaki Gunnam\n",
        "Jeff Harter\n",
        "\n",
        "Descriptive Terms: Manager\n",
        "------------------------------------\n",
        "Hyunhee (Ryan) Cho\n",
        "Thomas Lin\n",
        "Jenny Tran\n",
        "\n",
        "Descriptive Terms: President\n",
        "-----------------------------------------\n",
        "James Curleigh\n",
        "Larry Maye\n",
        "Gillian Wang\n",
        "Chip Bergh\n",
        "\n",
        "Descriptive Terms: Engineer, Software\n",
        "-------------------------------------------------------------\n",
        "Anh Mai\n",
        "Howard Haotian Bai\n",
        "Omar Rehmane\n",
        "\n",
        "Descriptive Terms: Associate\n",
        "---------------------------------------------\n",
        "Jonas Andersen\n",
        "Cathy Hwang\n",
        "Cecilia Yu Chung Chang\n",
        "Phi Nguyen\n",
        "\n",
        "Descriptive Terms: Assistant, Teacher\n",
        "------------------------------------------------------------\n",
        "Wendy Li\n",
        "Jana Hopkins\n",
        "\n",
        "Descriptive Terms: Analysis\n",
        "----------------------------------------\n",
        "Winnie Ip\n",
        "Michael Goico\n",
        "\n",
        "Descriptive Terms: Customer, Service\n",
        "--------------------------------------------------------------------------\n",
        "Yammy Kung\n",
        "Debbie Chew\n",
        "\n",
        "Descriptive Terms: Marketing\n",
        "----------------------------------------------------------------------------------------\n",
        "Connie Phu\n",
        "Elizabeth Sur\n",
        "Summer Sang-a Kim\n",
        "Kylie Foo\n",
        "Phi Nguyen\n",
        "Tiffany Chiao\n",
        "\n",
        "Descriptive Terms: Manager\n",
        "-------------------------------------\n",
        "Hyunhee (Ryan) Cho\n",
        "Jonathan Lee\n",
        "Thomas Lin\n",
        "\n",
        "Descriptive Terms: Operations\n",
        "----------------------------------------------------------------\n",
        "Brian Fukumoto\n",
        "Dawn Miedler\n",
        "Justin Yu\n",
        "Zhewen(Wendy) Hu\n",
        "\n",
        "Descriptive Terms: Operations, Manager,, Business\n",
        "------------------------------------------------------------------------------------------------------\n",
        "Molly Amble Kihanya\n",
        "John Holgate\n",
        "\n",
        "Descriptive Terms: Marketing\n",
        "-------------------------------------------\n",
        "Deanne Chen\n",
        "Tiffany Chiao\n",
        "\n",
        "Descriptive Terms: Teacher\n",
        "-----------------------------------------\n",
        "Wendy Li\n",
        "Bill Hiddleson\n",
        "\n",
        "Descriptive Terms: Business\n",
        "-----------------------------------------------------------------------------------------------------\n",
        "Deidre Quan\n",
        "John Holgate\n",
        "Simon Tiu\n",
        "\n",
        "Descriptive Terms: Analyst, Business\n",
        "-----------------------------------------------------------------------------------------\n",
        "Deidre Quan\n",
        "Sylvia Tang\n",
        "Simon Tiu\n",
        "\n",
        "Descriptive Terms: Designer\n",
        "---------------------------------------------------------------\n",
        "Darren Chan\n",
        "Francis Chen\n",
        "Jessica Gross\n",
        "\n",
        "Descriptive Terms: Associate\n",
        "-----------------------------------------\n",
        "Alexander Ramirez\n",
        "Jonas Andersen\n",
        "Cathy Hwang\n",
        "Cecilia Yu Chung Chang\n",
        "\n",
        "Descriptive Terms: Director\n",
        "-----------------------------------------\n",
        "David Su\n",
        "Clare Tong\n",
        "\n",
        "Descriptive Terms: Student, Graduate\n",
        "-------------------------------------------------------------------\n",
        "Dennis Wai\n",
        "Alan Huynh\n",
        "\n",
        "Descriptive Terms: Analyst\n",
        "----------------------------------------------------------------------------\n",
        "Vineet Baid\n",
        "Leo Wong\n",
        "Devon Jue\n",
        "Sylvia Tang\n",
        "Jenny Jiang\n",
        "\n",
        "Descriptive Terms: Development, Product\n",
        "------------------------------------------------------------------------\n",
        "Tim McAtee\n",
        "Bethany Johnson\n",
        "\n",
        "Descriptive Terms: Research\n",
        "-------------------------------------------\n",
        "Cheng Lu\n",
        "Rosa Ma\n",
        "Winnie Ip\n",
        "Xiangjiu Wang\n",
        "Jonathan Wong\n",
        "Candace Wong-Sing\n",
        "\n",
        "Descriptive Terms: Manager\n",
        "---------------------------------------\n",
        "Hyunhee (Ryan) Cho\n",
        "Thomas Lin\n",
        "Yeqing (Ching-Ching) Liu\n",
        "\n",
        "Descriptive Terms: Associate\n",
        "-----------------------------------------------------------------------------------\n",
        "Miranda Yanglei Pan\n",
        "Jonas Andersen\n",
        "Cathy Hwang\n",
        "Jennifer Chen\n",
        "Cecilia Yu Chung Chang\n",
        "\n",
        "Descriptive Terms: Manager\n",
        "------------------------------------------\n",
        "Hyunhee (Ryan) Cho\n",
        "Charlie Nguyen\n",
        "Thomas Lin\n",
        "\n",
        "Descriptive Terms: Manager\n",
        "----------------------------------\n",
        "Hyunhee (Ryan) Cho\n",
        "Henry Chen\n",
        "Thomas Lin\n",
        "\n",
        "Descriptive Terms: Associate\n",
        "-------------------------------------------\n",
        "Jessica Lukrich\n",
        "Jonas Andersen\n",
        "Cathy Hwang\n",
        "Cecilia Yu Chung Chang\n",
        "\n",
        "Descriptive Terms: Product, Management\n",
        "------------------------------------------------------------------\n",
        "George Nguyen\n",
        "Phi Nguyen\n",
        "\n",
        "Descriptive Terms: Recruiter\n",
        "----------------------------------------------\n",
        "Susan Ruan\n",
        "Christian Bada\n",
        "\n",
        "Descriptive Terms: Chief, Officer\n",
        "---------------------------------------------------------------\n",
        "Ric Kostick\n",
        "Marissa Teitelman\n",
        "Len Bargellini\n",
        "Larry Maye\n",
        "Chip Bergh\n",
        "\n",
        "Descriptive Terms: Marketing\n",
        "------------------------------------------\n",
        "George Nguyen\n",
        "Tiffany Chiao\n",
        "\n",
        "Descriptive Terms: Investment, Analyst\n",
        "--------------------------------------------------------------------\n",
        "Kobe Li\n",
        "Frances Bo\n",
        "Daniel Ma\n",
        "\n",
        "Descriptive Terms: Director\n",
        "---------------------------------------------------------------\n",
        "Marjorie DeGraca\n",
        "Kylie Foo\n",
        "Clare Tong\n",
        "Jesse Krieger\n",
        "\n",
        "Descriptive Terms: Manager\n",
        "-----------------------------------------\n",
        "Hyunhee (Ryan) Cho\n",
        "Charlie Wong\n",
        "Thomas Lin\n",
        "\n",
        "Descriptive Terms: Account, Associate\n",
        "--------------------------------------------------------------------\n",
        "Ryan Shi\n",
        "Jenny Tang\n",
        "\n",
        "Descriptive Terms: Researcher\n",
        "---------------------------------------------------\n",
        "Edward Kuang\n",
        "Kareem Ascha\n",
        "Jonathan Gu\n",
        "\n",
        "Descriptive Terms: Associate\n",
        "---------------------------------------------\n",
        "Jonas Andersen\n",
        "Kevin Chuc\n",
        "Cathy Hwang\n",
        "Cecilia Yu Chung Chang\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 88
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Incorporating random sampling can improve performance of the nested loops in Example 12**"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "import csv\n",
      "import random\n",
      "from nltk.metrics.distance import jaccard_distance\n",
      "\n",
      "# XXX: Place your \"Outlook CSV\" formatted file of connections from \n",
      "# http://www.linkedin.com/people/export-settings at the following\n",
      "# location: resources/ch03-linkedin/my_connections.csv\n",
      "\n",
      "CSV_FILE = os.path.join(\"resources\", \"ch03-linkedin\", 'my_connections.csv')\n",
      "\n",
      "# Tweak this distance threshold and try different distance calculations \n",
      "# during experimentation\n",
      "DISTANCE_THRESHOLD = 0.6\n",
      "DISTANCE = jaccard_distance\n",
      "\n",
      "# Adjust sample size as needed to reduce the runtime of the\n",
      "# nested loop that invokes the DISTANCE function\n",
      "SAMPLE_SIZE = 500\n",
      "\n",
      "def cluster_contacts_by_title(csv_file):\n",
      "\n",
      "    transforms = [\n",
      "        ('Sr.', 'Senior'),\n",
      "        ('Sr', 'Senior'),\n",
      "        ('Jr.', 'Junior'),\n",
      "        ('Jr', 'Junior'),\n",
      "        ('CEO', 'Chief Executive Officer'),\n",
      "        ('COO', 'Chief Operating Officer'),\n",
      "        ('CTO', 'Chief Technology Officer'),\n",
      "        ('CFO', 'Chief Finance Officer'),\n",
      "        ('VP', 'Vice President'),\n",
      "        ]\n",
      "\n",
      "    separators = ['/', ' and ', '&']\n",
      "\n",
      "    csvReader = csv.DictReader(open(csv_file), delimiter=',', quotechar='\"')\n",
      "    contacts = [row for row in csvReader]\n",
      "\n",
      "    # Normalize and/or replace known abbreviations\n",
      "    # and build up list of common titles\n",
      "\n",
      "    all_titles = []\n",
      "    for i, _ in enumerate(contacts):\n",
      "        if contacts[i]['Job Title'] == '':\n",
      "            contacts[i]['Job Titles'] = ['']\n",
      "            continue\n",
      "        titles = [contacts[i]['Job Title'].strip()]\n",
      "        for title in titles:\n",
      "            for separator in separators:\n",
      "                if title.find(separator) >= 0:\n",
      "                    titles.remove(title.strip())\n",
      "                    titles.extend([title.strip() for title in title.split(separator)\n",
      "                                  if title.strip() != ''])\n",
      "\n",
      "        for transform in transforms:\n",
      "            titles = [title.replace(*transform) for title in titles]\n",
      "        contacts[i]['Job Titles'] = titles\n",
      "        all_titles.extend(titles)\n",
      "\n",
      "    all_titles = list(set(all_titles))\n",
      "    clusters = {}\n",
      "    for title1 in all_titles:\n",
      "        clusters[title1] = []\n",
      "        for sample in xrange(SAMPLE_SIZE):\n",
      "            title2 = all_titles[random.randint(0, len(all_titles)-1)]\n",
      "            if title2 in clusters[title1] or clusters.has_key(title2) and title1 \\\n",
      "                in clusters[title2]:\n",
      "                continue\n",
      "            distance = DISTANCE(set(title1.split()), set(title2.split()))\n",
      "            if distance < DISTANCE_THRESHOLD:\n",
      "                clusters[title1].append(title2)\n",
      "\n",
      "    # Flatten out clusters\n",
      "\n",
      "    clusters = [clusters[title] for title in clusters if len(clusters[title]) > 1]\n",
      "\n",
      "    # Round up contacts who are in these clusters and group them together\n",
      "\n",
      "    clustered_contacts = {}\n",
      "    for cluster in clusters:\n",
      "        clustered_contacts[tuple(cluster)] = []\n",
      "        for contact in contacts:\n",
      "            for title in contact['Job Titles']:\n",
      "                if title in cluster:\n",
      "                    clustered_contacts[tuple(cluster)].append('%s %s'\n",
      "                            % (contact['First Name'], contact['Last Name']))\n",
      "\n",
      "    return clustered_contacts\n",
      "\n",
      "\n",
      "clustered_contacts = cluster_contacts_by_title(CSV_FILE)\n",
      "print clustered_contacts\n",
      "for titles in clustered_contacts:\n",
      "    common_titles_heading = 'Common Titles: ' + ', '.join(titles)\n",
      "\n",
      "    descriptive_terms = set(titles[0].split())\n",
      "    for title in titles:\n",
      "        descriptive_terms.intersection_update(set(title.split()))\n",
      "    descriptive_terms_heading = 'Descriptive Terms: ' \\\n",
      "        + ', '.join(descriptive_terms)\n",
      "    print descriptive_terms_heading\n",
      "    print '-' * max(len(descriptive_terms_heading), len(common_titles_heading))\n",
      "    print '\\n'.join(clustered_contacts[titles])\n",
      "    print"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{('Manager', 'DC Manager'): ['Hyunhee (Ryan) Cho', 'Henry Chen', 'Thomas Lin'], ('Management Consultant', 'Consultant'): ['Jay Tong', 'Janaki Gunnam', 'Jeff Harter'], ('Associate Account Executive', 'Search Account Associate'): ['Ryan Shi', 'Jenny Tang'], ('EVice President', 'President'): ['James Curleigh', 'Larry Maye', 'Gillian Wang', 'Chip Bergh'], ('Associate', 'Finance Associate'): ['Jessica Lukrich', 'Jonas Andersen', 'Cathy Hwang', 'Cecilia Yu Chung Chang'], ('Software Engineer', 'Associate Software Engineer'): ['Anh Mai', 'Howard Haotian Bai', 'Omar Rehmane'], ('Marketing Associate', 'Associate'): ['Jonas Andersen', 'Cathy Hwang', 'Cecilia Yu Chung Chang', 'Phi Nguyen'], ('Product Marketing', 'Marketing'): ['Deanne Chen', 'Tiffany Chiao'], ('Analysis', 'Analysis Intern'): ['Winnie Ip', 'Michael Goico'], ('Executive Director', 'Director'): ['Marjorie DeGraca', 'Clare Tong', 'Jesse Krieger'], ('Director', 'Marketing Director'): ['Kylie Foo', 'Clare Tong'], ('Assistant Language Teacher', 'Teacher Assistant'): ['Wendy Li', 'Jana Hopkins'], ('Teacher', 'Teacher Assistant'): ['Wendy Li', 'Bill Hiddleson'], ('Associate', 'Sales Associate'): ['Alexander Ramirez', 'Jonas Andersen', 'Cathy Hwang', 'Cecilia Yu Chung Chang'], ('Business Technology Analyst', 'Business Analyst', 'Business Operations Analyst'): ['Deidre Quan', 'Sylvia Tang', 'Simon Tiu'], ('Manager', 'House Manager'): ['Hyunhee (Ryan) Cho', 'Jonathan Lee', 'Thomas Lin'], ('Independent Designer', 'Graphic Designer', 'Designer'): ['Darren Chan', 'Francis Chen', 'Jessica Gross'], ('Healthcare Recruiter', 'Recruiter'): ['Susan Ruan', 'Christian Bada'], ('Analyst', 'Business Analyst', 'Project Analyst', 'Financial Analyst'): ['Vineet Baid', 'Leo Wong', 'Devon Jue', 'Sylvia Tang', 'Jenny Jiang'], ('Manager', 'Portfolio Manager'): ['Hyunhee (Ryan) Cho', 'Charlie Wong', 'Thomas Lin'], ('Business Operations Manager, Worldwide Sales Group, Legal', 'Manager, Business Operations'): ['Molly Amble Kihanya', 'John Holgate'], ('Product Development', 'Project Manager, Product Development'): ['Tim McAtee', 'Bethany Johnson'], ('Research', 'Research Assistant'): ['Cheng Lu', 'Rosa Ma', 'Winnie Ip', 'Xiangjiu Wang', 'Jonathan Wong', 'Candace Wong-Sing'], ('Project Manager', 'Manager'): ['Hyunhee (Ryan) Cho', 'Thomas Lin', 'Yeqing (Ching-Ching) Liu'], ('RDP Product Management', 'SpareOne Product Management'): ['George Nguyen', 'Phi Nguyen'], ('Operations Intern', 'Operations', 'Revenue Operations'): ['Brian Fukumoto', 'Dawn Miedler', 'Justin Yu', 'Zhewen(Wendy) Hu'], ('Graduate Student Intern', 'Graduate Student Researcher'): ['Dennis Wai', 'Alan Huynh'], ('Production Manager', 'Manager'): ['Hyunhee (Ryan) Cho', 'Charlie Nguyen', 'Thomas Lin'], ('Marketing', 'Marketing Coordinator', 'Marketing Intern', 'Marketing Associate', 'Marketing Director'): ['Connie Phu', 'Elizabeth Sur', 'Summer Sang-a Kim', 'Kylie Foo', 'George Nguyen', 'Phi Nguyen', 'Tiffany Chiao'], ('Associate', 'Specialty Associate'): ['Jonas Andersen', 'Kevin Chuc', 'Cathy Hwang', 'Cecilia Yu Chung Chang'], ('Investment Banking Analyst', 'Senior Investment Analyst'): ['Kobe Li', 'Frances Bo', 'Daniel Ma'], ('Associate Quality Assurance Engineer', 'Associate', 'Assurance Associate'): ['Miranda Yanglei Pan', 'Jonas Andersen', 'Cathy Hwang', 'Jennifer Chen', 'Cecilia Yu Chung Chang'], ('Business Operations Analyst', 'Manager, Business Operations', 'Business Technology Analyst'): ['Deidre Quan', 'John Holgate', 'Simon Tiu'], ('Undergraduate Researcher', 'Researcher'): ['Edward Kuang', 'Kareem Ascha', 'Jonathan Gu']}\n",
        "Descriptive Terms: Manager\n",
        "----------------------------------\n",
        "Hyunhee (Ryan) Cho\n",
        "Henry Chen\n",
        "Thomas Lin\n",
        "\n",
        "Descriptive Terms: Consultant\n",
        "------------------------------------------------\n",
        "Jay Tong\n",
        "Janaki Gunnam\n",
        "Jeff Harter\n",
        "\n",
        "Descriptive Terms: Account, Associate\n",
        "--------------------------------------------------------------------\n",
        "Ryan Shi\n",
        "Jenny Tang\n",
        "\n",
        "Descriptive Terms: President\n",
        "-----------------------------------------\n",
        "James Curleigh\n",
        "Larry Maye\n",
        "Gillian Wang\n",
        "Chip Bergh\n",
        "\n",
        "Descriptive Terms: Associate\n",
        "-------------------------------------------\n",
        "Jessica Lukrich\n",
        "Jonas Andersen\n",
        "Cathy Hwang\n",
        "Cecilia Yu Chung Chang\n",
        "\n",
        "Descriptive Terms: Engineer, Software\n",
        "-------------------------------------------------------------\n",
        "Anh Mai\n",
        "Howard Haotian Bai\n",
        "Omar Rehmane\n",
        "\n",
        "Descriptive Terms: Associate\n",
        "---------------------------------------------\n",
        "Jonas Andersen\n",
        "Cathy Hwang\n",
        "Cecilia Yu Chung Chang\n",
        "Phi Nguyen\n",
        "\n",
        "Descriptive Terms: Marketing\n",
        "-------------------------------------------\n",
        "Deanne Chen\n",
        "Tiffany Chiao\n",
        "\n",
        "Descriptive Terms: Analysis\n",
        "----------------------------------------\n",
        "Winnie Ip\n",
        "Michael Goico\n",
        "\n",
        "Descriptive Terms: Director\n",
        "-------------------------------------------\n",
        "Marjorie DeGraca\n",
        "Clare Tong\n",
        "Jesse Krieger\n",
        "\n",
        "Descriptive Terms: Director\n",
        "-------------------------------------------\n",
        "Kylie Foo\n",
        "Clare Tong\n",
        "\n",
        "Descriptive Terms: Assistant, Teacher\n",
        "------------------------------------------------------------\n",
        "Wendy Li\n",
        "Jana Hopkins\n",
        "\n",
        "Descriptive Terms: Teacher\n",
        "-----------------------------------------\n",
        "Wendy Li\n",
        "Bill Hiddleson\n",
        "\n",
        "Descriptive Terms: Associate\n",
        "-----------------------------------------\n",
        "Alexander Ramirez\n",
        "Jonas Andersen\n",
        "Cathy Hwang\n",
        "Cecilia Yu Chung Chang\n",
        "\n",
        "Descriptive Terms: Analyst, Business\n",
        "-----------------------------------------------------------------------------------------\n",
        "Deidre Quan\n",
        "Sylvia Tang\n",
        "Simon Tiu\n",
        "\n",
        "Descriptive Terms: Manager\n",
        "-------------------------------------\n",
        "Hyunhee (Ryan) Cho\n",
        "Jonathan Lee\n",
        "Thomas Lin\n",
        "\n",
        "Descriptive Terms: Designer\n",
        "---------------------------------------------------------------\n",
        "Darren Chan\n",
        "Francis Chen\n",
        "Jessica Gross\n",
        "\n",
        "Descriptive Terms: Recruiter\n",
        "----------------------------------------------\n",
        "Susan Ruan\n",
        "Christian Bada\n",
        "\n",
        "Descriptive Terms: Analyst\n",
        "----------------------------------------------------------------------------\n",
        "Vineet Baid\n",
        "Leo Wong\n",
        "Devon Jue\n",
        "Sylvia Tang\n",
        "Jenny Jiang\n",
        "\n",
        "Descriptive Terms: Manager\n",
        "-----------------------------------------\n",
        "Hyunhee (Ryan) Cho\n",
        "Charlie Wong\n",
        "Thomas Lin\n",
        "\n",
        "Descriptive Terms: Operations, Manager,, Business\n",
        "------------------------------------------------------------------------------------------------------\n",
        "Molly Amble Kihanya\n",
        "John Holgate\n",
        "\n",
        "Descriptive Terms: Development, Product\n",
        "------------------------------------------------------------------------\n",
        "Tim McAtee\n",
        "Bethany Johnson\n",
        "\n",
        "Descriptive Terms: Research\n",
        "-------------------------------------------\n",
        "Cheng Lu\n",
        "Rosa Ma\n",
        "Winnie Ip\n",
        "Xiangjiu Wang\n",
        "Jonathan Wong\n",
        "Candace Wong-Sing\n",
        "\n",
        "Descriptive Terms: Manager\n",
        "---------------------------------------\n",
        "Hyunhee (Ryan) Cho\n",
        "Thomas Lin\n",
        "Yeqing (Ching-Ching) Liu\n",
        "\n",
        "Descriptive Terms: Product, Management\n",
        "------------------------------------------------------------------\n",
        "George Nguyen\n",
        "Phi Nguyen\n",
        "\n",
        "Descriptive Terms: Operations\n",
        "----------------------------------------------------------------\n",
        "Brian Fukumoto\n",
        "Dawn Miedler\n",
        "Justin Yu\n",
        "Zhewen(Wendy) Hu\n",
        "\n",
        "Descriptive Terms: Student, Graduate\n",
        "-------------------------------------------------------------------\n",
        "Dennis Wai\n",
        "Alan Huynh\n",
        "\n",
        "Descriptive Terms: Manager\n",
        "------------------------------------------\n",
        "Hyunhee (Ryan) Cho\n",
        "Charlie Nguyen\n",
        "Thomas Lin\n",
        "\n",
        "Descriptive Terms: Marketing\n",
        "----------------------------------------------------------------------------------------------------------\n",
        "Connie Phu\n",
        "Elizabeth Sur\n",
        "Summer Sang-a Kim\n",
        "Kylie Foo\n",
        "George Nguyen\n",
        "Phi Nguyen\n",
        "Tiffany Chiao\n",
        "\n",
        "Descriptive Terms: Associate\n",
        "---------------------------------------------\n",
        "Jonas Andersen\n",
        "Kevin Chuc\n",
        "Cathy Hwang\n",
        "Cecilia Yu Chung Chang\n",
        "\n",
        "Descriptive Terms: Investment, Analyst\n",
        "--------------------------------------------------------------------\n",
        "Kobe Li\n",
        "Frances Bo\n",
        "Daniel Ma\n",
        "\n",
        "Descriptive Terms: Associate\n",
        "-----------------------------------------------------------------------------------\n",
        "Miranda Yanglei Pan\n",
        "Jonas Andersen\n",
        "Cathy Hwang\n",
        "Jennifer Chen\n",
        "Cecilia Yu Chung Chang\n",
        "\n",
        "Descriptive Terms: Business\n",
        "-----------------------------------------------------------------------------------------------------\n",
        "Deidre Quan\n",
        "John Holgate\n",
        "Simon Tiu\n",
        "\n",
        "Descriptive Terms: Researcher\n",
        "---------------------------------------------------\n",
        "Edward Kuang\n",
        "Kareem Ascha\n",
        "Jonathan Gu\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 97
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**How to export data (contained in the \"clustered contacts\" variable) to power faceted display as outlined in Figure 3.**"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import json\n",
      "import os\n",
      "from IPython.display import IFrame\n",
      "from IPython.core.display import display\n",
      "\n",
      "data = {\"label\" : \"name\", \"temp_items\" : {}, \"items\" : []} \n",
      "for titles in clustered_contacts:\n",
      "    descriptive_terms = set(titles[0].split())\n",
      "    for title in titles:\n",
      "        descriptive_terms.intersection_update(set(title.split()))\n",
      "    descriptive_terms = ', '.join(descriptive_terms)\n",
      "\n",
      "    if data['temp_items'].has_key(descriptive_terms):\n",
      "        data['temp_items'][descriptive_terms].extend([{'name' : cc } for cc \n",
      "            in clustered_contacts[titles]])\n",
      "    else:\n",
      "        data['temp_items'][descriptive_terms] = [{'name' : cc } for cc \n",
      "            in clustered_contacts[titles]]\n",
      "\n",
      "for descriptive_terms in data['temp_items']:\n",
      "    data['items'].append({\"name\" : \"%s (%s)\" % (descriptive_terms, \n",
      "        len(data['temp_items'][descriptive_terms]),),\n",
      "                              \"children\" : [i for i in \n",
      "                              data['temp_items'][descriptive_terms]]})\n",
      "\n",
      "del data['temp_items']\n",
      "\n",
      "# Open the template and substitute the data\n",
      "\n",
      "TEMPLATE = 'resources/ch03-linkedin/viz/dojo_tree.html.template'                                                \n",
      "OUT = 'resources/ch03-linkedin/viz/dojo_tree.html'\n",
      "\n",
      "viz_file = 'files/resources/ch03-linkedin/viz/dojo_tree.html'\n",
      "\n",
      "t = open(TEMPLATE).read()\n",
      "f = open(OUT, 'w')\n",
      "f.write(t % json.dumps(data, indent=4))\n",
      "f.close()\n",
      "\n",
      "# IPython Notebook can serve files and display them into\n",
      "# inline frames. Prepend the path with the 'files' prefix\n",
      "\n",
      "display(IFrame(viz_file, '400px', '600px'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "\n",
        "        <iframe\n",
        "            width=\"400px\"\n",
        "            height=600px\"\n",
        "            src=\"files/resources/ch03-linkedin/viz/dojo_tree.html\"\n",
        "            frameborder=\"0\"\n",
        "            allowfullscreen\n",
        "        ></iframe>\n",
        "        "
       ],
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "<IPython.lib.display.IFrame at 0x13c69e80>"
       ]
      }
     ],
     "prompt_number": 99
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**How to export data to power a dendogram and node-link tree visualization as outlined in Figure 4.**"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import cluster"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 102
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "import csv\n",
      "import random\n",
      "from nltk.metrics.distance import jaccard_distance\n",
      "from cluster import HierarchicalClustering\n",
      "\n",
      "# XXX: Place your \"Outlook CSV\" formatted file of connections from \n",
      "# http://www.linkedin.com/people/export-settings at the following\n",
      "# location: resources/ch03-linkedin/my_connections.csv\n",
      "\n",
      "CSV_FILE = os.path.join(\"resources\", \"ch03-linkedin\", 'my_connections.csv')\n",
      "\n",
      "OUT_FILE = 'resources/ch03-linkedin/viz/d3-data.json'\n",
      "\n",
      "# Tweak this distance threshold and try different distance calculations \n",
      "# during experimentation\n",
      "DISTANCE_THRESHOLD = 0.6\n",
      "DISTANCE = jaccard_distance\n",
      "\n",
      "# Adjust sample size as needed to reduce the runtime of the\n",
      "# nested loop that invokes the DISTANCE function\n",
      "SAMPLE_SIZE = 500\n",
      "\n",
      "def cluster_contacts_by_title(csv_file):\n",
      "\n",
      "    transforms = [\n",
      "        ('Sr.', 'Senior'),\n",
      "        ('Sr', 'Senior'),\n",
      "        ('Jr.', 'Junior'),\n",
      "        ('Jr', 'Junior'),\n",
      "        ('CEO', 'Chief Executive Officer'),\n",
      "        ('COO', 'Chief Operating Officer'),\n",
      "        ('CTO', 'Chief Technology Officer'),\n",
      "        ('CFO', 'Chief Finance Officer'),\n",
      "        ('VP', 'Vice President'),\n",
      "        ]\n",
      "\n",
      "    separators = ['/', 'and', '&']\n",
      "\n",
      "    csvReader = csv.DictReader(open(csv_file), delimiter=',', quotechar='\"')\n",
      "    contacts = [row for row in csvReader]\n",
      "\n",
      "    # Normalize and/or replace known abbreviations\n",
      "    # and build up list of common titles\n",
      "\n",
      "    all_titles = []\n",
      "    for i, _ in enumerate(contacts):\n",
      "        if contacts[i]['Job Title'] == '':\n",
      "            contacts[i]['Job Titles'] = ['']\n",
      "            continue\n",
      "        titles = [contacts[i]['Job Title']]\n",
      "        for title in titles:\n",
      "            for separator in separators:\n",
      "                if title.find(separator) >= 0:\n",
      "                    titles.remove(title)\n",
      "                    titles.extend([title.strip() for title in title.split(separator)\n",
      "                                  if title.strip() != ''])\n",
      "\n",
      "        for transform in transforms:\n",
      "            titles = [title.replace(*transform) for title in titles]\n",
      "        contacts[i]['Job Titles'] = titles\n",
      "        all_titles.extend(titles)\n",
      "\n",
      "    all_titles = list(set(all_titles))\n",
      "    \n",
      "    # Define a scoring function\n",
      "    def score(title1, title2): \n",
      "        return DISTANCE(set(title1.split()), set(title2.split()))\n",
      "\n",
      "    # Feed the class your data and the scoring function\n",
      "    hc = HierarchicalClustering(all_titles, score)\n",
      "\n",
      "    # Cluster the data according to a distance threshold\n",
      "    clusters = hc.getlevel(DISTANCE_THRESHOLD)\n",
      "\n",
      "    # Remove singleton clusters\n",
      "    clusters = [c for c in clusters if len(c) > 1]\n",
      "\n",
      "    # Round up contacts who are in these clusters and group them together\n",
      "\n",
      "    clustered_contacts = {}\n",
      "    for cluster in clusters:\n",
      "        clustered_contacts[tuple(cluster)] = []\n",
      "        for contact in contacts:\n",
      "            for title in contact['Job Titles']:\n",
      "                if title in cluster:\n",
      "                    clustered_contacts[tuple(cluster)].append('%s %s'\n",
      "                            % (contact['First Name'], contact['Last Name']))\n",
      "\n",
      "    return clustered_contacts\n",
      "\n",
      "def display_output(clustered_contacts):\n",
      "    \n",
      "    for titles in clustered_contacts:\n",
      "        common_titles_heading = 'Common Titles: ' + ', '.join(titles)\n",
      "\n",
      "        descriptive_terms = set(titles[0].split())\n",
      "        for title in titles:\n",
      "            descriptive_terms.intersection_update(set(title.split()))\n",
      "        descriptive_terms_heading = 'Descriptive Terms: ' \\\n",
      "            + ', '.join(descriptive_terms)\n",
      "        print descriptive_terms_heading\n",
      "        print '-' * max(len(descriptive_terms_heading), len(common_titles_heading))\n",
      "        print '\\n'.join(clustered_contacts[titles])\n",
      "        print\n",
      "\n",
      "def write_d3_json_output(clustered_contacts):\n",
      "    \n",
      "    json_output = {'name' : 'My LinkedIn', 'children' : []}\n",
      "\n",
      "    for titles in clustered_contacts:\n",
      "\n",
      "        descriptive_terms = set(titles[0].split())\n",
      "        for title in titles:\n",
      "            descriptive_terms.intersection_update(set(title.split()))\n",
      "\n",
      "        json_output['children'].append({'name' : ', '.join(descriptive_terms)[:30], \n",
      "                                    'children' : [ {'name' : c.decode('utf-8', 'replace')} for c in clustered_contacts[titles] ] } )\n",
      "    \n",
      "        f = open(OUT_FILE, 'w')\n",
      "        f.write(json.dumps(json_output, indent=1))\n",
      "        f.close()\n",
      "    \n",
      "clustered_contacts = cluster_contacts_by_title(CSV_FILE)\n",
      "display_output(clustered_contacts)\n",
      "write_d3_json_output(clustered_contacts)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "ValueError",
       "evalue": "list.remove(x): x not in list",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-103-4e2f36a6bc62>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    121\u001b[0m         \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 123\u001b[1;33m \u001b[0mclustered_contacts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcluster_contacts_by_title\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCSV_FILE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    124\u001b[0m \u001b[0mdisplay_output\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclustered_contacts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[0mwrite_d3_json_output\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclustered_contacts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m<ipython-input-103-4e2f36a6bc62>\u001b[0m in \u001b[0;36mcluster_contacts_by_title\u001b[1;34m(csv_file)\u001b[0m\n\u001b[0;32m     53\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mseparator\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mseparators\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mtitle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseparator\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m                     \u001b[0mtitles\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m                     titles.extend([title.strip() for title in title.split(separator)\n\u001b[0;32m     57\u001b[0m                                   if title.strip() != ''])\n",
        "\u001b[1;31mValueError\u001b[0m: list.remove(x): x not in list"
       ]
      }
     ],
     "prompt_number": 103
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Once you've run the code and produced the output for the dendogram and node-link tree visualizations, here's one way to serve it.**"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "from IPython.display import IFrame\n",
      "from IPython.core.display import display\n",
      "\n",
      "# IPython Notebook can serve files and display them into\n",
      "# inline frames. Prepend the path with the 'files' prefix\n",
      "\n",
      "viz_file = 'files/resources/ch03-linkedin/viz/node_link_tree.html'\n",
      "\n",
      "# XXX: Another visualization you could try:\n",
      "#viz_file = 'files/resources/ch03-linkedin/viz/dendogram.html'\n",
      "\n",
      "display(IFrame(viz_file, '100%', '600px'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "\n",
        "        <iframe\n",
        "            width=\"100%\"\n",
        "            height=600px\"\n",
        "            src=\"files/resources/ch03-linkedin/viz/node_link_tree.html\"\n",
        "            frameborder=\"0\"\n",
        "            allowfullscreen\n",
        "        ></iframe>\n",
        "        "
       ],
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "<IPython.lib.display.IFrame at 0x13c50240>"
       ]
      }
     ],
     "prompt_number": 104
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Example 13. Clustering your LinkedIn professional network based upon the locations of your connections and emitting KML output for visualization with Google Earth"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "import sys\n",
      "import json\n",
      "from urllib2 import HTTPError\n",
      "from geopy import geocoders\n",
      "from cluster import KMeansClustering, centroid\n",
      "\n",
      "# A helper function to munge data and build up an XML tree.\n",
      "# It references some code tucked away in another directory, so we have to\n",
      "# add that directory to the PYTHONPATH for it to be picked up.\n",
      "sys.path.append(os.path.join(os.getcwd(), \"resources\", \"ch03-linkedin\"))\n",
      "from linkedin__kml_utility import createKML\n",
      "\n",
      "# XXX: Try different values for K to see the difference in clusters that emerge\n",
      "\n",
      "K = 3\n",
      "\n",
      "# XXX: Get an API key and pass it in here. See https://www.bingmapsportal.com.\n",
      "GEO_API_KEY = ''\n",
      "g = geocoders.Bing(GEO_API_KEY)\n",
      "\n",
      "# Load this data from where you've previously stored it\n",
      "\n",
      "CONNECTIONS_DATA = 'resources/ch03-linkedin/linkedin_connections.json'\n",
      "\n",
      "OUT_FILE = \"resources/ch03-linkedin/viz/linkedin_clusters_kmeans.kml\"\n",
      "\n",
      "# Open up your saved connections with extended profile information\n",
      "# or fetch them again from LinkedIn if you prefer\n",
      "\n",
      "connections = json.loads(open(CONNECTIONS_DATA).read())['values']\n",
      "\n",
      "locations = [c['location']['name'] for c in connections if c.has_key('location')]\n",
      "\n",
      "# Some basic transforms may be necessary for geocoding services to function properly\n",
      "# Here are a couple that seem to help.\n",
      "\n",
      "transforms = [('Greater ', ''), (' Area', '')]\n",
      "\n",
      "# Step 1 - Tally the frequency of each location\n",
      "\n",
      "coords_freqs = {}\n",
      "for location in locations:\n",
      "\n",
      "    if not c.has_key('location'): continue\n",
      "    \n",
      "    # Avoid unnecessary I/O and geo requests by building up a cache\n",
      "\n",
      "    if coords_freqs.has_key(location):\n",
      "        coords_freqs[location][1] += 1\n",
      "        continue\n",
      "    transformed_location = location\n",
      "\n",
      "    for transform in transforms:\n",
      "        transformed_location = transformed_location.replace(*transform)\n",
      "        \n",
      "        # Handle potential I/O errors with a retry pattern...\n",
      "        \n",
      "        while True:\n",
      "            num_errors = 0\n",
      "            try:\n",
      "                results = g.geocode(transformed_location, exactly_one=False)\n",
      "                break\n",
      "            except HTTPError, e:\n",
      "                num_errors += 1\n",
      "                if num_errors >= 3:\n",
      "                    sys.exit()\n",
      "                print >> sys.stderr, e\n",
      "                print >> sys.stderr, 'Encountered an urllib2 error. Trying again...'\n",
      "                \n",
      "        for result in results:\n",
      "            # Each result is of the form (\"Description\", (X,Y))\n",
      "            coords_freqs[location] = [result[1], 1]\n",
      "            break # Disambiguation strategy is \"pick first\"\n",
      "\n",
      "# Step 2 - Build up data structure for converting locations to KML            \n",
      "            \n",
      "# Here, you could optionally segment locations by continent or country\n",
      "# so as to avoid potentially finding a mean in the middle of the ocean.\n",
      "# The k-means algorithm will expect distinct points for each contact, so\n",
      "# build out an expanded list to pass it.\n",
      "\n",
      "expanded_coords = []\n",
      "for label in coords_freqs:\n",
      "    # Flip lat/lon for Google Earth\n",
      "    ((lat, lon), f) = coords_freqs[label]\n",
      "    expanded_coords.append((label, [(lon, lat)] * f))\n",
      "\n",
      "# No need to clutter the map with unnecessary placemarks...\n",
      "\n",
      "kml_items = [{'label': label, 'coords': '%s,%s' % coords[0]} for (label,\n",
      "             coords) in expanded_coords]\n",
      "\n",
      "# It would also be helpful to include names of your contacts on the map\n",
      "\n",
      "for item in kml_items:\n",
      "    item['contacts'] = '\\n'.join(['%s %s.' % (c['firstName'], c['lastName'])\n",
      "        for c in connections if c.has_key('location') and \n",
      "                                c['location']['name'] == item['label']])\n",
      "\n",
      "# Step 3 - Cluster locations and extend the KML data structure with centroids\n",
      "    \n",
      "cl = KMeansClustering([coords for (label, coords_list) in expanded_coords\n",
      "                      for coords in coords_list])\n",
      "\n",
      "centroids = [{'label': 'CENTROID', 'coords': '%s,%s' % centroid(c)} for c in\n",
      "             cl.getclusters(K)]\n",
      "\n",
      "kml_items.extend(centroids)\n",
      "\n",
      "# Step 4 - Create the final KML output and write it to a file\n",
      "\n",
      "kml = createKML(kml_items)\n",
      "\n",
      "f = open(OUT_FILE, 'w')\n",
      "f.write(kml)\n",
      "f.close()\n",
      "\n",
      "print 'Data written to ' + OUT"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}